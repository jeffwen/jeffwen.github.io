<!DOCTYPE html>
<html lang="en">

<head>
  <!-- ## for client-side less
  <link rel="stylesheet/less" type="text/css" href="http://jeffwen.github.io/theme/css/style.less">
  <script src="http://cdnjs.cloudflare.com/ajax/libs/less.js/1.7.3/less.min.js" type="text/javascript"></script>
  -->
  <link rel="stylesheet" type="text/css" href="http://jeffwen.github.io/theme/css/style.css">
  <link rel="stylesheet" type="text/css" href="http://jeffwen.github.io/theme/css/pygments.css">
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=PT+Sans|PT+Serif|PT+Mono">
  <link rel="stylesheet" type="text/css" href="http://jeffwen.github.io/theme/css/custom.css">

  <!-- <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script> -->
  <!-- <script src="/theme/typed.js-master/js/typed.js"></script> -->

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Jeff Wen">
  <meta name="description" content="Posts and writings by Jeff Wen">

  <!-- <script> -->
  <!--     jQuery(function($){ -->
  <!--     $(".element").typed({ -->
  <!--       strings: ["aspiring data scientist.", "problem solver.","wannabe tinkerer."], -->
  <!--       typeSpeed: 50 -->
  <!--     }); -->
  <!--     }); -->
      
  <!-- </script> -->

  <link href="http://jeffwen.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Jeff Wen Atom" />

<meta name="keywords" content="">

  <title>
    Jeff Wen
&ndash; Making Census Data Exciting (Part 2)  </title>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-70808160-1', 'auto');
  ga('send', 'pageview');

</script>
<!--   <style> -->
<!--      .typed-cursor{ -->
<!--      opacity: 1; -->
<!--      font-weight: 100; -->
<!--     -webkit-animation: blink 0.7s infinite; -->
<!--     -moz-animation: blink 0.7s infinite; -->
<!--      animation: blink 0.7s infinite; -->
<!--      font-size: 1.5rem; -->
<!--      vertical-align:middle; -->
<!-- } -->
<!-- @keyframes blink{ -->
<!--     0% { opacity:1; } -->
<!--     50% { opacity:0; } -->
<!--     100% { opacity:1; } -->
<!-- } -->
<!-- @-webkit-keyframes blink{ -->
<!--     0% { opacity:1; } -->
<!--     50% { opacity:0; } -->
<!--     100% { opacity:1; } -->
<!-- } -->
<!-- @-moz-keyframes blink{ -->
<!--     0% { opacity:1; } -->
<!--     50% { opacity:0; } -->
<!--     100% { opacity:1; } -->
<!--      } -->

<!--      </style> -->



</head>

<body>
  <aside>
    <div id="user_meta">
      <a href="http://jeffwen.github.io">
        <img src="http://jeffwen.github.io/images/jeff_logo.png" id="user_logo" alt="logo">
      </a>
      <h2><a href="http://jeffwen.github.io">Jeff Wen</a></h2>
      <p>data scientist, problem solver, tinkerer</p>
      <!-- <p class="element" style="display:inline-block;"></div> -->
      <ul>
        <li><a href="http://jeffwen.github.io/pages/about-me.html">About Me</a></li>
        <li><a href="http://jeffwen.github.io/pages/photography.html">Photography</a></li>
        <li><a href="https://www.linkedin.com/in/wenjeff" target="_blank">LinkedIn</a></li>
        <li><a href="https://github.com/jeffwen" target="_blank">GitHub</a></li>
        <li><a href="mailto:jeff.li.wen@gmail.com" target="_blank">Email</a></li>
      </ul>
    </div>
  </aside>

  <main>
    <!--<header> 
      <p>
      <a href="http://jeffwen.github.io">Index</a> &brvbar; <a href="http://jeffwen.github.io/archives.html">Archives</a>
      &brvbar; <a href="http://jeffwen.github.io/feeds/all.atom.xml">Atom</a>
      </p>
    </header>-->

<article>
  <div class="article_title">
    <h3><a href="http://jeffwen.github.io/2016/03/18/making_census_data_exciting_part_2">Making Census Data Exciting (Part 2)</a></h3>
  </div>
  <div class="article_text">
    <p><em>March 18, 2016</em></p>
<p>In this post, I discuss the results of the work from the <a href="/2016/02/27/making_census_data_exciting_part_1">first post</a>. That first post was a bit lengthy and went into the details of getting the PostgreSQL set up, but that was all necessary to be able to query the data to set up the <a href="/html/dashboard.html">dashboard</a> (a screenshot is shown below, you can click on multiple things at once...cross filter charts)!</p>
<p><a href="/html/dashboard.html"><img alt="Dashboard" src="/images/dashboard.png"></a></p>
<h3>Problem Statement</h3>
<p>So the goal of the project was to see if <a href="https://archive.ics.uci.edu/ml/datasets/Census+Income">census data</a> could be used in an interesting manner. While discussing possible problems that could be solved, our team figured that it would be interesting to use the data as if we had just acquired a freelance employment company. Let me make this more clear:</p>
<ol>
<li>The parent company (a job posting company, think Monster.com), had just acquired a freelance job posting company (they have many freelance, gig type job postings)</li>
<li>The parent company has a database of existing users but because it was not focused on freelance and gig type jobs, the database does not have hours worked per week as a feature for its users</li>
<li>Machine learning would be used to predict how many hours an individual works (we bucketed this into &lt; 40 hours or &gt;= 40 hours)</li>
<li>Ultimately, in the hypothetical world, we would then target individuals that (we predicted) worked &lt; 40 hours with the part-time job postings (from the acquired company)</li>
</ol>
<p>After the prediction, was the visualization aspect that would help our hypothetical company's managers to slice and dice data as they wanted.</p>
<h3>Approach</h3>
<p>As part of the problem, I wanted to use PostgreSQL to get used to using it in a remote environment so that I could learn to store my data remotely (hence the previous post). However, the next step was to get the data out of the database so that it could be manipulated and massaged for further analysis.</p>
<p>For this, Psycopg2 was the best tool as it allowed for a pretty straight forward way to connect with the remote database. I wrote a Python script so that anyone on my team could quickly enter their login details and the script would ask for the SQL query. Then, the output would be a pandas dataframe of the data that was requested.</p>
<div class="highlight"><pre><span></span><span class="c1"># input must be strings</span>
<span class="k">def</span> <span class="nf">query_database</span><span class="p">(</span><span class="n">user</span><span class="p">,</span> <span class="n">dbname</span><span class="p">,</span> <span class="n">password</span><span class="p">,</span> <span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    dbname: database name</span>
<span class="sd">    user: username</span>
<span class="sd">    password: password for the user</span>
<span class="sd">    host: public dns</span>
<span class="sd">    port: typically for postgresql 5432</span>
<span class="sd">    returns a pandas dataframe of the given query</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Create connection with database</span>
        <span class="n">conn</span> <span class="o">=</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s2">&quot;dbname=&quot;</span><span class="o">+</span><span class="n">dbname</span><span class="o">+</span><span class="s2">&quot; user=&quot;</span><span class="o">+</span><span class="n">user</span><span class="o">+</span><span class="s2">&quot; password=&quot;</span><span class="o">+</span><span class="n">password</span><span class="o">+</span><span class="s2">&quot; host=&quot;</span><span class="o">+</span><span class="n">host</span><span class="o">+</span><span class="s2">&quot; port=&quot;</span><span class="o">+</span><span class="n">port</span><span class="p">)</span>
        <span class="k">print</span> <span class="s2">&quot;Connected&quot;</span>
        <span class="n">cur</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>

        <span class="c1"># Ask for user&#39;s SQL query</span>
        <span class="k">print</span> <span class="s2">&quot;Query please: &quot;</span>
        <span class="n">input_query</span> <span class="o">=</span> <span class="nb">raw_input</span><span class="p">()</span>

        <span class="c1"># Execute search query</span>
        <span class="n">cur</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">input_query</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">cur</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>

        <span class="c1"># Return dataframe</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">cur</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">df</span>

    <span class="k">except</span><span class="p">:</span>
        <span class="k">print</span> <span class="s2">&quot;Connection error or query mistake&quot;</span>
</pre></div>


<p>This made it quite easy to get the data out of the AWS database. The next steps was to clean the data and then run models to predict the hours worked.</p>
<p>In terms of cleaning the data, I wrote a function that took as input the previously outputted dataframe and returned a cleaned dataframe with white spaces removed from column headers, hours per week worked turned into a binary variable (&lt; 40 hours worked or &gt;= 40 hours worked), and other categorical variables turned into dummy variable columns. </p>
<h3>Predictions</h3>
<p>For the next step, we used the cleaned data as input to a couple different classification models. In order to test our models' accuracy we used 3 fold cross validation and achieved an accuracy score of ~70%. We could have used other error metrics but in our case we felt like the model was performing as good as we would have expected (we actually averaged couple models to achieve this accuracy).</p>
<p>Given the business problem, we were okay with 70% because for our hypothetical company, any classification of &lt; 40 hours worked (part-time) would mean that those individuals now had a lot of new job postings to browse (we acquired a freelance/ gig job posting company). Therefore, any exposure to these job postings would be better than nothing at all. Of course, in reality as we begin to get responses to the part-time job postings we would refine the prediction to make sure that we aren't showing part-time jobs to individuals who are actually working full-time (false positives).</p>
<h3>Dashboard</h3>
<p>The dashboard. Oh man. Okay, so a big part of this project was to practice using D3. Honestly, I had seen D3 used before, but I had no idea how flexible it was and how cool it was (the ease of use is something else). So I was quite excited to get my hands dirty.</p>
<p>The great thing about making dashboards is that there are lots of examples to draw from. For this particular dashboard, I used an example that <a href="http://bl.ocks.org/saraquigley/81807cb241cb4bbbaa6b">Sara Quigley</a> had made.</p>
<p>By the end, the resulting dashboard was quite different and I felt like I got to experiment with quite a lot of different techniques. <em>(as an aside: I am thankful for templates and also think that if possible you should make use of resources that are available, but make sure you know what is actually happening when you change things!)</em></p>
<p>I spent a lot of time reading through the code to try to understand how cross filter objects were being created and used. By the end, I had taken out a couple charts and also added a few items to the dashboard so that it fit out business problem</p>
<p>Also reading <a href="https://github.com/mbostock/d3/wiki/API-Reference">documentation</a> is probably one of the best ways to learn so I did a lot of that.</p>
<h3>Summary</h3>
<p>Overall, this project was quite interesting in that it had multiple moving parts that came together as a single dashboard deliverable. The awesome thing about this project was that it was pretty open ended so the problem statement that we came up with actually seemed like a real problem.</p>
<p>I spent most of my time on setting up the database, writing the script to pull data out, and tweaking/customizing the dashboard. In terms of takeaways, I realized that visualization is a large aspect of data science because the communication of results is vital to any problem. More specifically, a visually appealing tool can really help tell an impactful story (of course, the tool has to make sense).</p>
<p>Working with PostgreSQL and D3 helped me understand a more complete picture of the analytics space than just using Python. Moving forward, I would like to continue expanding my knowledge in these technologies and more!</p>
  </div>
  <div class="article_meta">
    <p>Posted on: March 18 2016</p>
    <p>Category: <a href="http://jeffwen.github.io/category/python/">Python</a>
    </p>
  </div>

  <div id="article_comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_identifier = "2016/03/18/making_census_data_exciting_part_2";
        (function() {
             var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
             dsq.src = 'http://jeffwen-blog.disqus.com/embed.js';
             (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
         })();
    </script>
  </div>

</article>

		     
    <div id="ending_message">
      <p>&copy; Jeff Wen. Built using <a href="http://getpelican.com" target="_blank">Pelican</a>. Theme by Giulio Fidente on <a href="https://github.com/gfidente/pelican-svbhack" target="_blank">github</a>. &brvbar; <a href="http://jeffwen.github.io/archives.html">Archives</a> </p>
    </div>
  </main>

<!-- automatically include javasccript -->

  
  <script>
<!-- setting up the theater view box for the individual images -->
$('.grid').magnificPopup({
	delegate: 'a',
        type: 'image',
closeBtnInside: false,
	gallery: {
		enabled: true,
		navigateByImgClick: true,
		preload: [1,2]
	}
});

<!-- setting up the isotope grid for the photo gallery images -->
var $grid = $('.grid').isotope({
itemSelector: '.picture',
    masonry:{
columnWidth: 180,
gutter:0
    }
});

$grid.on("mouseover mouseout",".picture",function() {
  // change size of item by toggling gigante class
  $(this).toggleClass('gigante');
  $grid.isotope('layout');
});

  </script>
 
</body>

</html>