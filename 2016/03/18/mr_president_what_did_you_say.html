<!DOCTYPE html>
<html lang="en">

<head>
  <!-- ## for client-side less
  <link rel="stylesheet/less" type="text/css" href="http://jeffwen.github.io/theme/css/style.less">
  <script src="http://cdnjs.cloudflare.com/ajax/libs/less.js/1.7.3/less.min.js" type="text/javascript"></script>
  -->
  <link rel="stylesheet" type="text/css" href="http://jeffwen.github.io/theme/css/style.css">
  <link rel="stylesheet" type="text/css" href="http://jeffwen.github.io/theme/css/pygments.css">
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=PT+Sans|PT+Serif|PT+Mono">

  <!-- <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script> -->
  <!-- <script src="/theme/typed.js-master/js/typed.js"></script> -->

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Jeff Wen">
  <meta name="description" content="Posts and writings by Jeff Wen">

  <!-- <script> -->
  <!--     jQuery(function($){ -->
  <!--     $(".element").typed({ -->
  <!--       strings: ["aspiring data scientist.", "problem solver.","wannabe tinkerer."], -->
  <!--       typeSpeed: 50 -->
  <!--     }); -->
  <!--     }); -->
      
  <!-- </script> -->

  <link href="http://jeffwen.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Jeff Wen Atom" />

<meta name="keywords" content="">

  <title>
    Jeff Wen
&ndash; Mr. President, what did you say?  </title>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-70808160-1', 'auto');
  ga('send', 'pageview');

</script>
<!--   <style> -->
<!--      .typed-cursor{ -->
<!--      opacity: 1; -->
<!--      font-weight: 100; -->
<!--     -webkit-animation: blink 0.7s infinite; -->
<!--     -moz-animation: blink 0.7s infinite; -->
<!--      animation: blink 0.7s infinite; -->
<!--      font-size: 1.5rem; -->
<!--      vertical-align:middle; -->
<!-- } -->
<!-- @keyframes blink{ -->
<!--     0% { opacity:1; } -->
<!--     50% { opacity:0; } -->
<!--     100% { opacity:1; } -->
<!-- } -->
<!-- @-webkit-keyframes blink{ -->
<!--     0% { opacity:1; } -->
<!--     50% { opacity:0; } -->
<!--     100% { opacity:1; } -->
<!-- } -->
<!-- @-moz-keyframes blink{ -->
<!--     0% { opacity:1; } -->
<!--     50% { opacity:0; } -->
<!--     100% { opacity:1; } -->
<!--      } -->

<!--      </style> -->
</head>

<body>
  <aside>
    <div id="user_meta">
      <a href="http://jeffwen.github.io">
        <img src="http://jeffwen.github.io/images/jeff_logo.png" alt="logo">
      </a>
      <h2><a href="http://jeffwen.github.io">Jeff Wen</a></h2>
      <p>aspiring data scientist, problem solver, wannabe tinkerer</p>
      <!-- <p class="element" style="display:inline-block;"></div> -->
      <ul>
        <li><a href="http://jeffwen.github.io/pages/about-me.html">About Me</a></li>
        <li><a href="https://www.linkedin.com/in/wenjeff" target="_blank">LinkedIn</a></li>
        <li><a href="https://github.com/jeffwen" target="_blank">GitHub</a></li>
        <li><a href="mailto:jeff.li.wen@gmail.com" target="_blank">Email</a></li>
      </ul>
    </div>
  </aside>

  <main>
    <!--<header> 
      <p>
      <a href="http://jeffwen.github.io">Index</a> &brvbar; <a href="http://jeffwen.github.io/archives.html">Archives</a>
      &brvbar; <a href="http://jeffwen.github.io/feeds/all.atom.xml">Atom</a>
      </p>
    </header>-->

<article>
  <div class="article_title">
    <h3><a href="http://jeffwen.github.io/2016/03/18/mr_president_what_did_you_say">Mr. President, what did you say?</a></h3>
  </div>
  <div class="article_text">
    <p><em>March 18, 2016</em></p>
<p>I know this may be annoying but embedding D3 in Pelican isn't the easiest thing so PLEASE click <a href="/html/president.html">here</a> to see the actual D3! The rest of the blog here will detail the process.</p>
<p>Also, yes very soon I will actually deploy these things somewhere so they aren't just static HTML pages...</p>
<p>But still, hope you enjoy!</p>
<p><a href="/html/president.html"><img alt="President Network" src="/images/president_network.png" /></a></p>
<h3>What are we doing here</h3>
<p>I would like to provide some details both for whoever is reading and also for myself so I remember this project.</p>
<p>This particular project was one of the most difficult to date for me because it required the use of a couple different technologies in unison and also with this project, I tried to actually build most of the D3 visualizations by myself. As a result, it took a bit of time and I am quite proud of the outcome!</p>
<p>The objectives of this project:</p>
<ol>
<li>Use MongoDB to store some semi-structured data (namely text data)</li>
<li>Perform some form of natural language processing over the collected data</li>
<li>Present the results in an interesting way</li>
</ol>
<p>The broader goal was to see if I could analyze text and see how presidents' were either similar or different in the topics that they discussed. I also wanted to identify if those topics changed across time.</p>
<h3>MongoDB</h3>
<p>MongoDB is really easy to get running. Remember that post about the <a href="/2016/02/27/making_census_data_exciting_part_1">census data</a>? Well let me just post a little bit of code to show how quick it is to set up MongoDB (granted, this is on my local machine and not on AWS...but still I'm trying to make a point so forgive me).</p>
<div class="highlight"><pre><span class="c"># install with homebrew (mac)</span>
brew install mongodb
<span class="c"># make a data directory (for mongo to write to)</span>
sudo mkdir /data/db
<span class="c"># change ownership for the directory and start the mongo server</span>
sudo chown your_username /data/db
mongod
</pre></div>


<p>Boom. After this you can just <code>mongoimport</code> entire <code>.json</code> files into your database as different collections or however you'd like. So all of that to say that it is definitely easier to get things set up and data into the database (not to say that SQL isn't good...they are good for different things).</p>
<p>With the database set up, I had to get my data.</p>
<h3>Presidential Data</h3>
<p>There were a couple sites that had some great resources, but the one that I ended up using was the UC Santa Barbara <a href="http://www.presidency.ucsb.edu/sou.php">American Presidency Project</a>. It has speeches, press releases, and much more dating back to President Washington.</p>
<p><a href="http://www.presidency.ucsb.edu/sou.php"><img alt="American Presidency Project" src="/images/presidency_project.png" /></a></p>
<p>While it would have been great to have some form of an API to make calls to and get nicely formatted data, I did not have that luxury in this case and so I scraped the data that I needed using BeautifulSoup. Usually, this wouldn't be the easiest part, but this time it was actually quite simple!</p>
<div class="highlight"><pre><span class="c"># make the request to the website</span>
<span class="k">def</span> <span class="nf">requester</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    url: url of the site to be scraped</span>
<span class="sd">    return: BeautifulSoup obejct of the scraped text</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">ok</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

<span class="c"># state of the union addresses urls</span>
<span class="k">def</span> <span class="nf">get_union_address_url</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">requester</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

    <span class="c"># only extract the links from the page that link to speeches</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">&#39;table&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">&#39;a&#39;</span><span class="p">,</span> <span class="n">href</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">&#39;.*/ws/index&#39;</span><span class="p">))</span>
    <span class="n">speech_urls</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">a</span><span class="p">:</span>
        <span class="n">speech_urls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">link</span><span class="p">[</span><span class="s">&#39;href&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">speech_urls</span>

<span class="c"># extract the text from the speeches as a dictionary</span>
<span class="k">def</span> <span class="nf">parse_union_address</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">requester</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">president</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">&#39;title&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;:&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="n">president</span> <span class="o">=</span> <span class="s">&#39;&#39;</span>
        <span class="n">title</span> <span class="o">=</span> <span class="s">&#39;&#39;</span>

    <span class="c"># create a dictionary with the details of interest</span>
    <span class="n">date</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">strptime</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">&#39;span&#39;</span><span class="p">,{</span><span class="s">&#39;class&#39;</span><span class="p">:</span><span class="s">&#39;docdate&#39;</span><span class="p">})</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s">&#39;%B </span><span class="si">%d</span><span class="s">, %Y&#39;</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">&#39;span&#39;</span><span class="p">,{</span><span class="s">&#39;class&#39;</span><span class="p">:</span><span class="s">&#39;displaytext&#39;</span><span class="p">})</span>

    <span class="c"># each paragraph is separated into (as it will be considered a document in later analyses)</span>
    <span class="n">text_list</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">text_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">text_list</span><span class="p">]</span>
    <span class="n">aDict</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;president&#39;</span><span class="p">:</span><span class="n">president</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span><span class="s">&#39;title&#39;</span><span class="p">:</span><span class="n">title</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span><span class="s">&#39;date&#39;</span><span class="p">:</span><span class="n">date</span><span class="p">,</span><span class="s">&#39;text&#39;</span><span class="p">:</span><span class="n">text_list</span><span class="p">,</span><span class="s">&#39;url&#39;</span><span class="p">:</span><span class="n">url</span><span class="p">,</span><span class="s">&#39;speech&#39;</span><span class="p">:</span><span class="s">&#39;State of the Union&#39;</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">aDict</span>
</pre></div>


<p>Those three functions above are a sample of the functions that I wrote to scrape the State of the Union Addresses from the website. I had similar functions to scrape Inaugural Addresses and press releases. After getting all the text, I created dictionaries with the details of the speeches and used <code>pymongo</code> to connect to mongoDB so that I could store the data.</p>
<p>It wasn't necessary to use mongoDB because I used Python to scrape the data and was going to manipulate the data in Python,but I wanted to learn how to use the database for future reference. Furthermore, in case anything happened I wouldn't have to rely on the pickled files I created (as an extra saftey measure...).</p>
<h3>Network Graph</h3>
<p>If you took a look at the HTML page that I linked to at the beginning with the network graph of the presidents, you'll notice that there are clusters of presidents. Initially, I hypothesized that the presidents would be clustered by their respective parties; however, I turned out to be really wrong! They were mostly clustered based by the period in which they were president. This makes sense and I will discuss this later.</p>
<p>So how did I generate those clusters? Well, let me start off by talking about how I got to clustering. </p>
<h4><em>Latent Semantic Indexing</em></h4>
<p>One of the interesting techniques that I wanted to use was <a href="https://en.wikipedia.org/wiki/Latent_semantic_indexing">latent semantic indexing</a>. Very basically, this technique uses matrix factorization (singular value decomposition) to map the documents into a vector space, then we specify the rank (kind of like the number of concepts that we want to keep). Afterwards, the passed in term frequency matrix is factorized into a term concept matrix, a square singular value matrix, and a concept document matrix. The concept document matrix can be thought of as a matrix that captures the latent 'concepts' within the documents.</p>
<p>I used the concept document matrix and computed the cosine similarity between each of the different vectors (in this case each president had his own vector that signified the concepts in his speeches and press releases). Then I created the connections by simply setting the threshold to &gt;= 0.75 (I experimented with this for a bit to see how the connections would turn out; a bit arbitrary, but if I had more time I would have kept all connections and used the weight/width of the connection to represent the cosine similarity).</p>
<h3>Taking a Step Back</h3>
<p>With the network created, I realized that the connections were actually based more on the time period in which the presidents served. So I added the color and labels to identify the presidents by the period in which they served. I also included the party toggle to show that my initial hypothesis was incorrect.</p>
<p>In order to learn more about what the presidents' talked about, I decided to dive down into the particular time periods. My thought was that if I could limit the president set to within the same time period, then some of the finer details of topics discussed would show up.</p>
<h4>Latent Dirichlet Allocation</h4>
<p><a href="/html/president.html"><img alt="LDA Topics" src="/images/lda_bubbles.png" /></a></p>
<p>In order to extract the topics that were discussed in the different speeches and press releases, I decided that it would be more accurate to run the analyses on separate paragraphs. When a president gives a State of the Union Address or Inaugural Address, each paragraph is typically a separate topic; therefore, I made each paragraph an individual document (if it was more than 10 words long).</p>
<p>I used <a href="http://jmlr.csail.mit.edu/papers/v3/blei03a.html">latent dirichlet allocation</a>, which is a probabilistic approach to generating topics. Very basically, we start by randomly assigning k topics to a document (a mixture of topics), then each word in the document to a topic. This is a fairly poor representation of the topics at this stage, but it improves by going through and updating the topic for each word by choosing a new topic with probability that the new topic generated this word (here is an <a href="https://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation/answer/Edwin-Chen-1?srid=CiUY">awesome explanation</a> that is a lot more clear! Go read! seriously!).</p>
<p>Therefore, for each paragraph I extracted the most likely topic words (from the LDA output). Just to finish things up, I connected these topic words back to the initial paragraphs so that I could see the paragraphs that LDA determined to be a certain topic.</p>
<h3>Summary</h3>
<p>This project took quite a bit of coordination and also learning because I was trying to use different technologies that I didn't have much experience with. However, it was one of the most fulfilling projects, because by the end I had something that not only summarized the analyses that I performed, but also an interactive demonstration so that others could explore as well.</p>
<p>With that said, there are definitely improvements to be made.</p>
<ol>
<li>It isn't long before you notice that some of the initial paragraphs in the scrolling text box are not paragraphs. Instead, there are headers, questions, and other irrelevant forms of text. These should be taken out because they do not really represent paragraphs that the presidents spoke</li>
<li>As an additional analyses, it would be interesting to run LDA on speeches that aren't State of the Union or Inaugural Addresses because these speeches are typically very broad ranging in topics discussed and therefore each president in the same period of time would most likely be discussing similar matters (think Obama and Bush talking about war...)</li>
</ol>
<p>Anyways, those are just a few that came to mind. I hope you enjoyed the post and the visualizations!</p>
  </div>
  <div class="article_meta">
    <p>Posted on: March 18 2016</p>
    <p>Category: <a href="http://jeffwen.github.io/category/python/">Python</a>
    </p>
  </div>

  <div id="article_comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_identifier = "2016/03/18/mr_president_what_did_you_say";
        (function() {
             var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
             dsq.src = 'http://jeffwen-blog.disqus.com/embed.js';
             (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
         })();
    </script>
  </div>

</article>

		     
    <div id="ending_message">
      <p>&copy; Jeff Wen. Built using <a href="http://getpelican.com" target="_blank">Pelican</a>. Theme by Giulio Fidente on <a href="https://github.com/gfidente/pelican-svbhack" target="_blank">github</a>. &brvbar; <a href="http://jeffwen.github.io/archives.html">Archives</a> </p>
    </div>
  </main>
</body>
</html>