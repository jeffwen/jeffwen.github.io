<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jeff Wen</title><link href="http://jeffwen.github.io/" rel="alternate"></link><link href="http://jeffwen.github.io/feeds/all.atom.xml" rel="self"></link><id>http://jeffwen.github.io/</id><updated>2017-03-28T20:41:00-07:00</updated><entry><title>Traffic Sign Recognition</title><link href="http://jeffwen.github.io/2017/03/28/traffic_signs" rel="alternate"></link><updated>2017-03-28T20:41:00-07:00</updated><author><name>Jeff Wen</name></author><id>tag:jeffwen.github.io,2017-03-28:2017/03/28/traffic_signs</id><summary type="html">&lt;p&gt;&lt;em&gt;March 28, 2017&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Traffic Sign Recognition&lt;/h2&gt;
&lt;p&gt;In this project, we classify &lt;a href="http://benchmark.ini.rub.de/?section=gtsrb&amp;amp;subsection=dataset"&gt;German traffic signs&lt;/a&gt;. The code for this project can be found in this &lt;a href="https://github.com/jeffwen/sdcnd_traffic_sign/blob/master/Traffic_Sign_Classifier.ipynb"&gt;IPython notebook&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The objective of this project is to ultimately design, train, and test a convolutional neural netowk (CNN) to see if we can accurately classify the traffic signs. Specifically, with image classification tasks the variability of input images might cause the model to perform poorly. In order to remedy this situation, we will consider preprocessing steps to ensure that the model is robust to varying input images. Furthermore, depending on how the model performs, we may need to consider regularization steps such as dropouts or L2 regularization. &lt;/p&gt;
&lt;p&gt;To start with, I use the &lt;a href="http://yann.lecun.com/exdb/lenet/"&gt;LeNet-5 architecture&lt;/a&gt; that was first published by Yann Lecun's lab in 1998. Eventually, I augmented the training set with rotated and zoomed images, normalized images, and included dropouts for the fully connected layers. This led to a final model that achieved ~95% on the validation set and ~94% on the test set. &lt;/p&gt;
&lt;h3&gt;Data Set Summary &amp;amp; Exploration&lt;/h3&gt;
&lt;p&gt;Before jumping into the model, we can take a look at some of the images within the dataset. &lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/example1.png" title="80 kph" /&gt; &lt;img alt="alt text" src="./images/media/example2.png" title="Straight or right" /&gt; &lt;img alt="alt text" src="./images/media/example3.png" title="Stop" /&gt; 
&lt;img alt="alt text" src="./images/media/example4.png" title="100 kph" /&gt; &lt;img alt="alt text" src="./images/media/example5.png" title="30 kph" /&gt; &lt;img alt="alt text" src="./images/media/example6.png" title="Beware ice/ snow" /&gt;&lt;/p&gt;
&lt;p&gt;The images vary quite a lot in terms of brightness/ we can imagine that the orientation of the images might also be quite different. More specifically, we can take a look at just stop signs and see that there is quite a lot of variation. &lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/stop1.png" title="Stop Sign" /&gt; &lt;img alt="alt text" src="./images/media/stop2.png" title="Stop Sign" /&gt; &lt;img alt="alt text" src="./images/media/stop3.png" title="Stop Sign" /&gt; 
&lt;img alt="alt text" src="./images/media/stop4.png" title="Stop Sign" /&gt; &lt;img alt="alt text" src="./images/media/stop5.png" title="Stop Sign" /&gt; &lt;img alt="alt text" src="./images/media/stop6.png" title="Stop Sign" /&gt;&lt;/p&gt;
&lt;p&gt;Additionally, we can take a look at how the traffic sign classes are distributed (to see if the classes are evenly balanced). Looking at the below histogram, it seems like there are some classes that are represented 7x as much as the least  represented class. Later on we might want to upsample the less represented classes to make the model more robust. &lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/histogram.png" title="Class Histogram" /&gt;&lt;/p&gt;
&lt;p&gt;Below are some summary statistics calculated from the dataset that we have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Number of training examples = &lt;code&gt;34799&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Number of validation examples = &lt;code&gt;4410&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Number of testing examples = &lt;code&gt;12630&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Image data shape = &lt;code&gt;(32, 32)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Number of classes = &lt;code&gt;43&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Data Preprocessing and Model Evaluation&lt;/h3&gt;
&lt;p&gt;The input data is rather varied in terms of lighting and orientation of images. In order to improve the accuracy of the model, we can implement some preprocessing steps on our images. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Grayscaling, Mean Subtraction, and Normalization&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;First of all, I implemented grayscaling of the traffic sign images. While there may be some information lost because the color information in the image might contain information about the traffic sign, grayscaling simplifies the 3 channels into a single channel, which can lead to quicker model training. Additionally, taking away the color channels might allow the CNN to "focus" on extracting the important non-color features better. &lt;/p&gt;
&lt;p&gt;After performing grayscaling, I performed mean subtraction and normalization of the image pixels. Specifically, in the cs231n &lt;a href="http://cs231n.github.io/neural-networks-2/"&gt;course notes&lt;/a&gt; Andrej Karpathy mentions that the standard preprocessing techniques involve mean subtraction &lt;code&gt;img = img - np.mean(img)&lt;/code&gt; and normalization &lt;code&gt;img = img / np.std(img)&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Before Processing Images&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/before_process.png" title="Before Processing" /&gt; &lt;img alt="alt text" src="./images/media/before_process2.png" title="Before Processing" /&gt; &lt;/p&gt;
&lt;p&gt;After Processing Images&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/after_process.png" title="After Processing" /&gt; &lt;img alt="alt text" src="./images/media/after_process2.png" title="After Processing" /&gt; &lt;/p&gt;
&lt;p&gt;At this point, model performed fairly well and better than the 93% on the validation set that was required in the grading rubric. To start with, the original LeNet-5 network applied to the colored images achieved ~88% on the validation set. Then the gray scaling, mean subtraction, and normalization combined with dropouts on the fully connected layers pushed the validation accuracy to ~95%. 
- I added the dropouts because looking at the original train vs. validation curve, the model shows strong overfitting. As to why the drops were only applied to the fully connected layers, looking at this &lt;a href="https://www.kaggle.com/c/state-farm-distracted-driver-detection/discussion/20201"&gt;kaggle question&lt;/a&gt; the author mentions that we usualy do not apply dropouts to the convolution layer because the convolution layer is meant to extract features and also does not have that many features to regularize.&lt;/p&gt;
&lt;p&gt;Original LeNet Architecture&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/train_valid_original.png" title="Train vs Validation Curve (Original)" /&gt; &lt;/p&gt;
&lt;p&gt;LeNet Architecture with Grayscaling, Normalization, and Dropouts&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/train_valid_gray_norm.png" title="Train vs Validation Curve (Grayscale, Normalization, Dropout)" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Model Evaluation and Deep Dive&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While the model is performing fairly well, we can dive deeper in to the performance of the model to figure out what is happening with the predictions. Specifically, below are the histogram and confusion matrix of validation actuals vs. the validation predicted. By looking at the histogram and confusion matrix, we can look at where the classifications are mistaken and what classes are typically wrong. &lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/actual_vs_pred_hist.png" title="Actual vs. Predicted Histogram" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/gray_norm_confusion.png" title="Confusion Matrix (grayscale, normalization, dropounts)" /&gt;&lt;/p&gt;
&lt;p&gt;If we look at the histogram above, we see that most of the bars are at about the same place. Similarly, it seems like the diagonal is quite well defined, which means that the CNN did fairly well! However, if we look at the off diagonal cells in the confusion matrix, we see that there are definitely misclassifications. For example, what is actually supposed to be class 0 gets misclassified as class 4 or class 16 gets misclassified as class 41. Below are sample images from these classes.&lt;/p&gt;
&lt;p&gt;Class 0 misclassified as Class 4&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/class0_class4_1.png" title="Class 0" /&gt; &lt;img alt="alt text" src="./images/media/class0_class4_2.png" title="Class 4" /&gt;&lt;/p&gt;
&lt;p&gt;Class 16 misclassified as Class 41&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/class16_class41_2.png" title="Class 16" /&gt; &lt;img alt="alt text" src="./images/media/class16_class41_1.png" title="Class 41" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Augmentation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;So it seems fairly reasonable, especially for the class 0 to class 4 example for the network to misclassify the images. It even looking at the gray and normalized images the differences between the two are not that drastic. In order to improve the model's performance on these, we can augment the dataset by creating more images with various operations like zooming and rotating the images. Note that it seems like the classes that are more often misclassified are also the classes with the fewest amount of data. This step took an unexpectedly long time because many additional images were created of the under represented classes. With these additional images, I retrained the model. Overall, 11915 additional images were created and a few of the additional images are shown below.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/new_gen_image.png" title="Processed Image" /&gt; &lt;img alt="alt text" src="./images/media/new_gen_image_1.png" title="Processed Image" /&gt;&lt;/p&gt;
&lt;p&gt;After training with the additional images and increasing the number of epochs to 25, the accuracy on the validation set increased to ~95%. The actual vs. predicted histogram and training/ validation curve also shows an improvement. If we look closely at the actual vs. predicted histogram, it seems like the classes that were misclassified previously are now more accurately classified, which means the data augmentation worked!&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/aws_histogram.png" title="Aws Histogram" /&gt; &lt;img alt="alt text" src="./images/media/aws_train_valid_curve.png" title="AWS Train Curve" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Iterative Model Building&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As evidenced above, the process of training, validating, and testing the model architecture took an extended amount of time. Mainly because after running the the model over the validation set, I would return to the preprocessing stages to experiment with various other methods for preprocessing. &lt;/p&gt;
&lt;p&gt;When fiddling with the model's hyperparameters, I had to switch over to use AWS to train the model because with the additional images and an increased number of epochs, the model was too slow to run on my local machine. Specifically, I launched a &lt;code&gt;g2.2xlarge&lt;/code&gt; Amazon EC2 instance and it took ~2-3 minutes to train on the 45,000+ image training set with 25 epochs.&lt;/p&gt;
&lt;p&gt;In terms of further improvement on the model, the training and validation curves are still fairly separated meaning the model is still overfitting. In the future, I will consider applying L2 regularization and/or increasing the dropout % to reduce the chance of overfitting.&lt;/p&gt;
&lt;h3&gt;Design and Test a Model Architecture&lt;/h3&gt;
&lt;p&gt;In terms of the model architecture that was used to achieve the results above, I used a modified version of the LeNet-5 architecture (shown below). The code used to build the CNN is under the "Model Architecture" section of the Jupyter Notebook. &lt;/p&gt;
&lt;p&gt;LeNet Architecture (Actual architecture is slightly different)&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/lenet.png" title="LeNet Architecture" /&gt;&lt;/p&gt;
&lt;p&gt;Specifically, the model had the following setup:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Layer&lt;/th&gt;
&lt;th align="center"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Input&lt;/td&gt;
&lt;td align="center"&gt;32x32x1 Grayscale/ Normalized image&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Convolution 5x5&lt;/td&gt;
&lt;td align="center"&gt;1x1 stride, valid padding, outputs 28x28x6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;RELU activation&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Max pooling&lt;/td&gt;
&lt;td align="center"&gt;2x2 stride, valid padding, outputs 14x14x6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Convolution 5x5&lt;/td&gt;
&lt;td align="center"&gt;1x1 stride, valid padding, outputs 10x10x16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;RELU activation&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Max pooling&lt;/td&gt;
&lt;td align="center"&gt;2x2 stride, valid padding, outputs 5x5x16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Fully connected&lt;/td&gt;
&lt;td align="center"&gt;400 input, 120 output&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;RELU activation&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Dropout&lt;/td&gt;
&lt;td align="center"&gt;0.6 keep probablility (training)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Fully connected&lt;/td&gt;
&lt;td align="center"&gt;120 input, 84 output&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;RELU activation&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Dropout&lt;/td&gt;
&lt;td align="center"&gt;0.6 keep probablility (training)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Fully connected&lt;/td&gt;
&lt;td align="center"&gt;84 input, 43 output&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The above architecture with &lt;code&gt;EPOCHS = 25&lt;/code&gt;, &lt;code&gt;BATCH_SIZE = 128&lt;/code&gt;, and &lt;code&gt;LEARNING_RATE = 0.001&lt;/code&gt; ended up doing fairly well achieving:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Training Set Accuracy: ~99.8%&lt;/li&gt;
&lt;li&gt;Validation Set Accuracy: ~95%&lt;/li&gt;
&lt;li&gt;Test Set Accuracy: ~94%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In terms of the optimizer used, I considered using various optimizers such as regular gradient descent, but one of the considerations for switching to the Adam optimizer was that the Adam optimizer takes into account "momentum". Specifically, the Adam optimizer (&lt;a href="http://sebastianruder.com/optimizing-gradient-descent/index.html#minibatchgradientdescent"&gt;read more here&lt;/a&gt;) takes "momentum" into account by keeping a decaying average of the past gradients, which usually provides quicker convergence. &lt;/p&gt;
&lt;h3&gt;Test a Model on New Images&lt;/h3&gt;
&lt;p&gt;In order to further test the model's performance on previously unseen images, I found 6 images from Google Maps Street View to test with the model. Looking at the images below, there are couple factors that might affect the model's ability to classify these new traffic signs. For example, the "Road Work" and "Road Narrows on the Right" signs are captured at an angle. This skew in the image might not get captured by the model because the training data might not have images that are similar. However, when building the training data (via augmenting more images) I tried to include rotated images to deal with this possibility. Additionally, the reduced brightness and skew in the "No Entry" image were potential problems for the classifer.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/new_internet_images.png" title="Internet Images" /&gt;&lt;/p&gt;
&lt;p&gt;I plotted the top 5 predictions (based on softmax probabilities) for the 6 different images.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="./images/media/softmax_prob_1.png" title="Softmax1" /&gt;
&lt;img alt="alt text" src="./images/media/softmax_prob_2.png" title="Softmax2" /&gt;
&lt;img alt="alt text" src="./images/media/softmax_prob_3.png" title="Softmax3" /&gt;
&lt;img alt="alt text" src="./images/media/softmax_prob_4.png" title="Softmax4" /&gt;
&lt;img alt="alt text" src="./images/media/softmax_prob_5.png" title="Softmax5" /&gt;
&lt;img alt="alt text" src="./images/media/softmax_prob_6.png" title="Softmax6" /&gt;&lt;/p&gt;
&lt;p&gt;From the results above, it seems like the concerns mentioned were actually handled fairly well by the classifier. Most of the images with the skew and brightness concerns are handled well and the probabilities also show that the model was not "unsure" between classes (except for the 80 kph vs 30 kph sign). The model achieved a ~83.3% accuracy with 5/6 images correctly classified. The 80 kph sign was misclassified as 30 kph, but this is understandable because the model might have mistaken the &lt;code&gt;8&lt;/code&gt; as a &lt;code&gt;3&lt;/code&gt;. When looking at the image, it seems quite obvious that the image is &lt;code&gt;80&lt;/code&gt;. Ultimately, I may have to add more 80 kph signs with various image translations to ensure the model does not mistakenly classify these signs.&lt;/p&gt;
&lt;p&gt;When compared to the test set, the unseen images has a lower accuracy, but it is because of the misclassification mentioned above. On the other images, the model is quite certain (high probability), while for the misclassified image has visible uncertianty (in the bar graphs of the probabilities). Overall, the model seemed to do quite well on unseen data!&lt;/p&gt;
&lt;h3&gt;Conclusions and Next Steps&lt;/h3&gt;
&lt;p&gt;This project was quite interesting and gave me the opportunity to learn more about Tensorflow, convolutional neual networks, and how to train, validate, and test a model using an Amazon EC2 instance. Additionally, I got the opportunity to experiment with preprocessing steps to improve the image classification and I learned the importance of augmenting under represented classes.&lt;/p&gt;
&lt;p&gt;While the model performed fairly well, there are improvements that can be made. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Further regularization: Based on the training and validation curves, the model can definitely be further regularized&lt;/li&gt;
&lt;li&gt;Data augmentation: While I experimented with rotation and zooming on images, it may have helped to further translate, crop, and manipulate images to increase the training set and increase the variety of input images&lt;/li&gt;
&lt;li&gt;Hyperparameter tuning: The model performed fairly well but with more time I could have increased the number of epochs or fiddled with the batch size further to see if the model performance improves&lt;/li&gt;
&lt;li&gt;Model architecture: The LeNet architecture is a good start, but with state-of-the-art advancements such as &lt;a href="https://github.com/tensorflow/models/tree/master/inception"&gt;Google's Inception-V3&lt;/a&gt; there are other architectures that might work even better&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ultimately, this was an exciting project that gave me the opportunity to bring together many different techniques and technologies to solve and interesting problem!&lt;/p&gt;</summary></entry><entry><title>Lane Finding from Video Feeds</title><link href="http://jeffwen.github.io/2017/02/23/lane_finding" rel="alternate"></link><updated>2017-02-23T22:41:00-08:00</updated><author><name>Jeff Wen</name></author><id>tag:jeffwen.github.io,2017-02-23:2017/02/23/lane_finding</id><summary type="html">&lt;p&gt;&lt;em&gt;February 23, 2017&lt;/em&gt;&lt;/p&gt;
&lt;h1&gt;Finding Lane Lines on the Road&lt;/h1&gt;
&lt;p&gt;The github repository with the associate IPython Notebook can be found &lt;a href="https://github.com/jeffwen/sdcnd_find_lanes"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Objective&lt;/h2&gt;
&lt;p&gt;The ultimate goal of this project was to be able to identify lane lines in both images and videos. Namely, to develop a pipeline that utilizes different computer vision techniques to mark the location of lane lines. The approach that I took explored multiple techniques to obtain the best results:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Color selection with OpenCV with different color maps&lt;ul&gt;
&lt;li&gt;Grayscale &lt;/li&gt;
&lt;li&gt;Hue, saturation, and light&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Gaussian blur to reduce noise&lt;/li&gt;
&lt;li&gt;Canny edge detection&lt;/li&gt;
&lt;li&gt;Hough line transformation&lt;/li&gt;
&lt;li&gt;Moving average of previous lane lines &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Color Manipulation&lt;/h2&gt;
&lt;p&gt;To start with, images came as screenshots from an onboard video feed.&lt;/p&gt;
&lt;p&gt;&lt;img alt="lane1" src="/images/solidWhiteRight.jpg" /&gt; 
&lt;img alt="lane2" src="/images/solidYellowLeft.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;The first step that I took was to turn the image to grayscale to make it easier to work, namely to reduce the number of channels to work with. However, when dealing with more challenging images such as lane lines that are on non-contrasting backgrounds (white or gray tarmac), the eventual pipeline for lane linea detection does not perform well. In order to improve the performance, I switched to using &lt;a href="https://en.wikipedia.org/wiki/HSL_and_HSV#HSL"&gt;hue, saturation, and light&lt;/a&gt; color space, which is better able to highlight the yellow and white lane lines.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Grayscale&lt;/em&gt;
&lt;img alt="gray" src="/images/challengeShadow_gray.jpg" /&gt; &lt;/p&gt;
&lt;p&gt;&lt;em&gt;HSL color space&lt;/em&gt;
&lt;img alt="hsl" src="/images/challengeShadow_hlsimage_pyplot.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;In the above image, we can see that the yellow lane is very clearly highlighted and the white line markings are also captured well when compared to the grayscale image. However, to further improve the performance of the processing pipeline, we can also select out the colors that we know we care about (in this case the yellow and white lines, which are now blue and green)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;## color selection for yellow and white, using the HSL color space&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;color_selection&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="n"&gt;hls_image&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cvtColor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;COLOR_RGB2HLS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;white_color&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inRange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hls_image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint8&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint8&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt; &lt;span class="c"&gt;## note that OpenCV uses BGR not RGB&lt;/span&gt;
    &lt;span class="n"&gt;yellow_color&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inRange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hls_image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint8&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint8&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;

    &lt;span class="n"&gt;combined_color_images&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bitwise_or&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;white_color&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yellow_color&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bitwise_and&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;combined_color_images&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In the above code, I first convert the color map from RGB to HSL. Then I use the &lt;code&gt;inRange&lt;/code&gt; function provided by OpenCV to select colors that fall into the white and yellow ranges. After that I combine the white and yellow masks together with the &lt;code&gt;bitwise_or&lt;/code&gt; function. &lt;/p&gt;
&lt;p&gt;With the above HSL image, we can now try to isolate the yellow and the white lines. While there are many different techniques that can be utilized here, I chose to detect the edges within the image using the Canny edge detection algorithm. &lt;/p&gt;
&lt;h2&gt;Edge Detection&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;HSL color selection&lt;/em&gt;
&lt;img alt="hsl" src="/images/challengeShadow_hsl.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Given the above image, the goal is to pick out the lane lines. In order to do this, I use the &lt;a href="https://en.wikipedia.org/wiki/Canny_edge_detector"&gt;canny edge detector&lt;/a&gt; algorithm. In short, the algorithm:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;1. Applies a gaussian filter to the image to reduce noise
2. Finds the gradients in both the horizontal and vertical directions
3. Non-maximum supression, which is a way to thin the detected edges by only keeping the maximum gradient values and setting others to 0
4. Determining potential edges by checking against a threshold 
5. Finish cleaning potential edges by checking in the potential edge is connected to an actual edge
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;While, the canny edge detector automatically applies &lt;a href="https://en.wikipedia.org/wiki/Gaussian_blur"&gt;gaussian blur&lt;/a&gt;, I applied gaussian blur outside of the edge detector so that I could have more freedom with the kernel parameter. After running the image through the blurring and edge detection functions, the image is as follows. Note, the input image to this is the HSL color converted image. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;HSL color selection with canny edge detection&lt;/em&gt;
&lt;img alt="hsl_canny" src="/images/challengeShadow_hslcanny.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;With the image above, we see that the lane lines are pretty well identified. It took a bit of trial and error to find suitable thresholds for the canny edge detector though the creator John Canny recommended a ratio of 1:2 or 1:3 for the low vs. high threshold. Although the image above seems to mark the lane lines quite well, there is still a lot of noise surrounding the lane that we do not care about. In order to address this, we can apply a region mask to just keep the area that we know contains the lane lines. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Region masking&lt;/em&gt;
&lt;img alt="region_bounds" src="/images/challengeShadow_regionmask.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;After applying the mask to the canny image, we get the following output. We can contrast this with the gray image after canny edge detection and the region selection. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Grayscale image with canny edge detection and region masking&lt;/em&gt;
&lt;img alt="region_canny_gray" src="/images/challengeShadow_grayregioncanny.jpg" /&gt; &lt;/p&gt;
&lt;p&gt;&lt;em&gt;HSL color selection with canny edge detection and region masking&lt;/em&gt;
&lt;img alt="region_canny" src="/images/challengeShadow_regioncanny.jpg" /&gt; &lt;/p&gt;
&lt;p&gt;As shown above, the HSL version provides a cleaner indication of the lane lines. Below are the functions used in processing the images.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;canny&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;low_threshold&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;high_threshold&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Applies the Canny transform&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Canny&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;low_threshold&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;high_threshold&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gaussian_blur&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Applies a Gaussian Noise kernel&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GaussianBlur&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;region_of_interest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;vertices&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Applies an image mask.&lt;/span&gt;

&lt;span class="sd"&gt;    Only keeps the region of the image defined by the polygon&lt;/span&gt;
&lt;span class="sd"&gt;    formed from `vertices`. The rest of the image is set to black.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="c"&gt;#defining a blank mask to start with&lt;/span&gt;
    &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros_like&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   

    &lt;span class="c"&gt;#defining a 3 channel or 1 channel color to fill the mask with depending on the input image&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;channel_count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;  &lt;span class="c"&gt;# i.e. 3 or 4 depending on your image&lt;/span&gt;
        &lt;span class="n"&gt;ignore_mask_color&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="p"&gt;,)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;channel_count&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;ignore_mask_color&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;255&lt;/span&gt;

    &lt;span class="c"&gt;#filling pixels inside the polygon defined by &amp;quot;vertices&amp;quot; with the fill color    &lt;/span&gt;
    &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fillPoly&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;vertices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ignore_mask_color&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c"&gt;#returning the image only where mask pixels are nonzero&lt;/span&gt;
    &lt;span class="n"&gt;masked_image&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bitwise_and&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;masked_image&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Hough Line Transform&lt;/h2&gt;
&lt;p&gt;Now that we have a collection of edges, we need to identify the lane lines within the image. The &lt;a href="https://en.wikipedia.org/wiki/Hough_transform"&gt;hough line transform&lt;/a&gt;, which was first invented to identify lines within images, is great for this task. To learn more about this algorithm, this &lt;a href="http://alyssaq.github.io/2014/understanding-hough-transform/"&gt;blog&lt;/a&gt; is a great resource. &lt;/p&gt;
&lt;p&gt;_HSL color selection with canny edge detection, region masking, and hough transform
&lt;img alt="hsl_hough" src="/images/challengeShadow_hlshoughimage_pyplot.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Pretty awesome! The lane lines have now been highlighted and boxed with the red lines. There are quite a few parameters that needed to be adjusted, but after adjusting the parameters, the algorithm is able to pick out the lines quite well. Note that the OpenCV version of the hough transform that we are using is the probabilistic version, which is an improvement over the original. In the IPython notebook, I use a different version of the &lt;code&gt;hough_lines&lt;/code&gt; function that simple outputs the lines as a vector rather than overlaying the lines over the initial image. &lt;/p&gt;
&lt;p&gt;Given the above image and specifically the hough lines, we now have a vector of multiple lines segments in the form of (x1,y1,x2,y2) endpoints. In order to draw lines on an image, we need a way to extrapolate an average line from the vector of endpoints.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;hough_lines_overlay&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rho&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;threshold&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_line_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_line_gap&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    `img` should be the output of a Canny transform.&lt;/span&gt;

&lt;span class="sd"&gt;    Returns an image with hough lines drawn.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;lines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HoughLinesP&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rho&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;threshold&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([]),&lt;/span&gt; &lt;span class="n"&gt;minLineLength&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;min_line_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxLineGap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;max_line_gap&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;line_img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;draw_lines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line_img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lines&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;line_img&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Lane Line Averaging&lt;/h2&gt;
&lt;p&gt;In order to find the average line on each side of the lane, we can first calculate the slope of each line segment and separate the positive and negative sloped lines, which represents the left and right lane lines. Then we can find the average of the left and right slopes and intercepts to get an average of the lanes. When I initially did this, the average was quite sensitive to outliers. I tried to adjust for the outliers by removing points that were greater than 1.5 standard deviations from the rest of the slopes. However, the averaged lines were still quite sensitive to the outliers. &lt;/p&gt;
&lt;p&gt;Ultimately, by calculating the line length and calculating the weighted average of the lane line, the output was much more stable and robust against spurious line segments that the hough transform identified. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;avg_lines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lines&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="n"&gt;neg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="c"&gt;## calculate slopes for each line to identify the positive and negative lines&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;lines&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y2&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;slope&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;y1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;intercept&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt;
            &lt;span class="n"&gt;line_length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;y2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;y1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;slope&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;line_length&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;neg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;neg&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;intercept&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line_length&lt;/span&gt;&lt;span class="p"&gt;]]),&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;slope&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;line_length&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="n"&gt;slope&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;intercept&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line_length&lt;/span&gt;&lt;span class="p"&gt;]]),&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c"&gt;## just keep the observations with slopes with 2 std dev&lt;/span&gt;
    &lt;span class="n"&gt;neg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;neg&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;to_keep_index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;neg&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
    &lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;to_keep_index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;

    &lt;span class="c"&gt;## weighted average of the slopes and intercepts based on the length of the line segment&lt;/span&gt;
    &lt;span class="n"&gt;neg_lines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;neg&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;neg&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:,:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;neg&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;neg&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
    &lt;span class="n"&gt;pos_lines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:,:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;neg_lines&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pos_lines&lt;/span&gt;

&lt;span class="c"&gt;## removing the outliers (adapted from http://stackoverflow.com/questions/11686720/is-there-a-numpy-builtin-to-reject-outliers-from-a-list)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;to_keep_index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obs&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obs&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obs&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The above function calculates the slope, intercept, and line length of each line segment. At this point, we can take the average lane lines from the above function and plot the lane lines onto the original image. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Final processed image&lt;/em&gt;
&lt;img alt="hsl_final" src="/images/challengeShadow_processed.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;It seems to have performed quite well! Below are a few other sample images of the outputs from the lane finding pipeline. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Sample processed images&lt;/em&gt;
&lt;img alt="solid_yellow" src="/images/solidYellowCurve_processed.jpg" /&gt; 
&lt;img alt="solid_white" src="/images/solidWhiteRight_processed.jpg" /&gt;&lt;/p&gt;
&lt;h2&gt;Applying Lane Finding to Videos&lt;/h2&gt;
&lt;p&gt;Now that we can identify and mark the lane lines within the image supplied, we can use the algorithm on a video, which is just a sequence of images. If we just apply the pipeline directly to the video, we get the following. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://vimeo.com/205495473"&gt;Lane Finding (Without Previous Averaging)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The video seems to show the lane lines without any problems, but when we take a closer look the lane line highlights are jittering and jumping across back and forth around the actual location of the lane line. While, the algorithm basically accomplishes the problem that we first set out to solve, maybe we can improve on this. &lt;/p&gt;
&lt;p&gt;Specifically, the lane lines coming from a video feed usually do not change dramatically from second to second. If we take this into account, we can "smooth" the lane lines plotted out by keeping a queue. With each frame of the video, we can pop off the oldest set of lane line endpoints. Then for all the remaining lane lines and the newest lane line, we take an average to get the "smoothed" lane line. &lt;/p&gt;
&lt;p&gt;Below is the code for the lane line detector and the link to the test videos.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://vimeo.com/205495845"&gt;Lane Finding - White Line (With Averaging)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://vimeo.com/205495681"&gt;Lane Finding - Yellow Line (With Averaging)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://vimeo.com/205495856"&gt;Lane Finding - Curve (With Averaging)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above videos show that the new detector with the lane line averaging works quite nicely! Although if there are drastic changes the algorithm does not follow those changes until a bit later, we can fiddle with this by changing the size of the queue.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;lane_detector&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prev_lane_lines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;find_mean_lines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lane_lines&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;prev_lane_lines&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

        &lt;span class="c"&gt;## add the new lane line&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;lane_lines&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;prev_lane_lines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lane_lines&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c"&gt;## only keep the 10 most recent lane lines&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prev_lane_lines&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;prev_lane_lines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c"&gt;## take the average of the past lane lines and the new ones&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prev_lane_lines&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prev_lane_lines&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pipeline&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;imshape&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;

        &lt;span class="c"&gt;## selecting yellow and white colors&lt;/span&gt;
        &lt;span class="n"&gt;color_selected_img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;color_selection&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c"&gt;## Define a kernel size and apply Gaussian smoothing&lt;/span&gt;
        &lt;span class="n"&gt;kernel_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;
        &lt;span class="n"&gt;blur_img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GaussianBlur&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;color_selected_img&lt;/span&gt;&lt;span class="p"&gt;,(&lt;/span&gt;&lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c"&gt;## apply canny edge detection&lt;/span&gt;
        &lt;span class="n"&gt;canny_img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;canny&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;blur_img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;low_threshold&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;high_threshold&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;160&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c"&gt;## apply region of interest&lt;/span&gt;
        &lt;span class="n"&gt;vertices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;imshape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]),(&lt;/span&gt;&lt;span class="n"&gt;imshape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*.&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imshape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mf"&gt;0.6&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;imshape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*.&lt;/span&gt;&lt;span class="mi"&gt;55&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imshape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mf"&gt;0.6&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;imshape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;imshape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])]],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;region_img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;region_of_interest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;canny_img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;vertices&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;vertices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c"&gt;## apply hough transformation&lt;/span&gt;
        &lt;span class="n"&gt;rho&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="c"&gt;# distance resolution in pixels of the Hough grid&lt;/span&gt;
        &lt;span class="n"&gt;theta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;180&lt;/span&gt; &lt;span class="c"&gt;# angular resolution in radians of the Hough grid&lt;/span&gt;
        &lt;span class="n"&gt;threshold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt; &lt;span class="c"&gt;# minimum number of votes (intersections in Hough grid cell)&lt;/span&gt;
        &lt;span class="n"&gt;min_line_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt; &lt;span class="c"&gt;#minimum number of pixels making up a line&lt;/span&gt;
        &lt;span class="n"&gt;max_line_gap&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;250&lt;/span&gt;   &lt;span class="c"&gt;# maximum gap in pixels between connectable line segments&lt;/span&gt;

        &lt;span class="n"&gt;lines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hough_lines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;region_img&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rho&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;threshold&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_line_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_line_gap&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c"&gt;## get the average slopes and intercepts for each lane line&lt;/span&gt;
        &lt;span class="n"&gt;slopes_intercepts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;avg_lines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lines&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c"&gt;# find the endpoints given the slopes and intercepts&lt;/span&gt;
        &lt;span class="n"&gt;endpoints&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gen_endpoints&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slopes_intercepts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c"&gt;## generate lane lines on a black image&lt;/span&gt;
        &lt;span class="n"&gt;lane_lines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gen_lane_lines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;endpoints&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_mean_lines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;endpoints&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prev_lane_lines&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

        &lt;span class="n"&gt;final_img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;weighted_img&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lane_lines&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;final_img&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Shortcomings &amp;amp; Next Steps&lt;/h2&gt;
&lt;p&gt;While the detector works fairly well for straight roads, there are limitations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Curved Roads&lt;/li&gt;
&lt;li&gt;Lane markings that are not yellow or white&lt;/li&gt;
&lt;li&gt;Different perspective &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In order to deal with these shortcomings, we would need to make the algorithm more robust to differences in the input video. For example, to deal with the curves in the road instead of setting a fixed length for the lane line highlights, which is currently 60% of the image height, we might be able to use the length of the identified line segment from th hough line transform as a proxy for how long the highlight should be. &lt;/p&gt;
&lt;p&gt;The yellow and white lane lines might be harder to deal with, but we can combine human input as well as computational methods. For example, if there are training images from roads in different areas with different colored markings, we can keep a "dictionary" of these lane colors and setup the algorithm to look for the colors that expected given the geographic region in consideration. &lt;/p&gt;
&lt;p&gt;The videos that were supplied as test videos were all basically filmed at the same angle and the roads were also fairly similar. However, if the vehicle was traveling over a hill or out of a trough the perspective would change. In these cases, the algorithm might not perform as well. In order to adjust for this, we can first apply a perspective normalization to the input video so that input would always have the same orientation and perspective. &lt;/p&gt;
&lt;p&gt;Overall, this project was interesting and fun! It incorporated a lot of techniques and concepts that have been available for many years, but is now being applied to interesting problems like self-driving cars. &lt;/p&gt;</summary></entry><entry><title>Visaurant: Reimagining the food search experience</title><link href="http://jeffwen.github.io/2016/05/02/visaurant" rel="alternate"></link><updated>2016-05-02T14:26:00-07:00</updated><author><name>Jeff Wen</name></author><id>tag:jeffwen.github.io,2016-05-02:2016/05/02/visaurant</id><summary type="html">&lt;p&gt;&lt;em&gt;May 02, 2016&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Visaurant Logo" src="/images/visaurant_logo.png" /&gt;
This blog post is a work in progress and will detail the process that I took to create the Visaurant project.&lt;/p&gt;
&lt;p&gt;Visaurant (as you can see in the video below) is a reimagination of the way users search through images that they are interested in. One prime use case for Visaurant is in sorting and filtering through food images (hence &lt;em&gt;VIS&lt;/em&gt; -ual rest- &lt;em&gt;AURANT&lt;/em&gt;).&lt;/p&gt;
&lt;h3&gt;Background&lt;/h3&gt;
&lt;p&gt;So why do we want a visual search application?&lt;/p&gt;
&lt;p&gt;Images represent a wealth of information. As cliche as it sounds, &lt;em&gt;'a picture is worth a thousand words'&lt;/em&gt; especially when it comes to looking for food items that seem appetizing. Speaking from personal experience, I often use apps like Yelp by:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Going to the images of a particular restaurant&lt;/li&gt;
&lt;li&gt;Looking for the pictures that look good&lt;/li&gt;
&lt;li&gt;Reading the caption&lt;/li&gt;
&lt;li&gt;Going back to the reviews to find the reviews regarding the item that I saw&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;While this process works, it is by no means streamlined. Having to go back and forth between the images, captions, and reviews is a hassle and quite often overwhelming because there are so many images to sift through. So although images are powerful and contain a lot of information, if the images are not ordered or organized then it becomes difficult to find what I care about (like the example below...).&lt;/p&gt;
&lt;p&gt;&lt;img alt="Yelp Restaurant Photos" src="/images/yelp_photo.png" /&gt;&lt;/p&gt;
&lt;p&gt;Visaurant aims to change that by:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Clustering visually similar images to allow users to quickly narrow down to images of interest&lt;/li&gt;
&lt;li&gt;Parsing through captions to extract reviews that are relevant to the image that was selected&lt;/li&gt;
&lt;/ol&gt;
&lt;iframe src="https://player.vimeo.com/video/165064797" width="640" height="344" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;

&lt;h4&gt;What is happening in the video?&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;User gets to select a group of images from a restaurant that looks interesting (4 selections)
&lt;img alt="Visaurant Selection" src="/images/visaurant_selection.png" /&gt;&lt;/li&gt;
&lt;li&gt;Recommendations will be made based on the user's selections&lt;/li&gt;
&lt;li&gt;User can once again select the restaurant that looks most appealing
&lt;img alt="Visaurant Recommendation" src="/images/visaurant_recommendation.png" /&gt;&lt;/li&gt;
&lt;li&gt;Restaurant specific page will show up allowing the user to hover over images that look interesting and images within the same visual cluster will be highlighted
&lt;img alt="Visaurant Highlight" src="/images/visaurant_highlight.png" /&gt;&lt;/li&gt;
&lt;li&gt;User can select an image and all images will be filtered for images in the same cluster
&lt;img alt="Visaurant Filtered" src="/images/visaurant_filtered.png" /&gt;&lt;/li&gt;
&lt;li&gt;After filtering down to a single cluster, user can select a specific image to bring up reviews that have matching words with the image's caption
&lt;img alt="Visaurant Caption" src="/images/visaurant_caption.png" /&gt;&lt;/li&gt;
&lt;/ol&gt;</summary></entry><entry><title>Mr. President, what did you say?</title><link href="http://jeffwen.github.io/2016/03/18/mr_president_what_did_you_say" rel="alternate"></link><updated>2016-03-18T22:18:00-07:00</updated><author><name>Jeff Wen</name></author><id>tag:jeffwen.github.io,2016-03-18:2016/03/18/mr_president_what_did_you_say</id><summary type="html">&lt;p&gt;&lt;em&gt;March 18, 2016&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I know this may be annoying but embedding D3 in Pelican isn't the easiest thing so PLEASE click &lt;a href="/html/president.html"&gt;here&lt;/a&gt; to see the actual D3! The rest of the blog here will detail the process.&lt;/p&gt;
&lt;p&gt;Also, yes very soon I will actually deploy these things somewhere so they aren't just static HTML pages...&lt;/p&gt;
&lt;p&gt;But still, hope you enjoy!&lt;/p&gt;
&lt;p&gt;&lt;a href="/html/president.html"&gt;&lt;img alt="President Network" src="/images/president_network.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;What are we doing here&lt;/h3&gt;
&lt;p&gt;I would like to provide some details both for whoever is reading and also for myself so I remember this project.&lt;/p&gt;
&lt;p&gt;This particular project was one of the most difficult to date for me because it required the use of a couple different technologies in unison and also with this project, I tried to actually build most of the D3 visualizations by myself. As a result, it took a bit of time and I am quite proud of the outcome!&lt;/p&gt;
&lt;p&gt;The objectives of this project:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use MongoDB to store some semi-structured data (namely text data)&lt;/li&gt;
&lt;li&gt;Perform some form of natural language processing over the collected data&lt;/li&gt;
&lt;li&gt;Present the results in an interesting way&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The broader goal was to see if I could analyze text and see how presidents' were either similar or different in the topics that they discussed. I also wanted to identify if those topics changed across time.&lt;/p&gt;
&lt;h3&gt;MongoDB&lt;/h3&gt;
&lt;p&gt;MongoDB is really easy to get running. Remember that post about the &lt;a href="/2016/02/27/making_census_data_exciting_part_1"&gt;census data&lt;/a&gt;? Well let me just post a little bit of code to show how quick it is to set up MongoDB (granted, this is on my local machine and not on AWS...but still I'm trying to make a point so forgive me).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# install with homebrew (mac)&lt;/span&gt;
brew install mongodb
&lt;span class="c"&gt;# make a data directory (for mongo to write to)&lt;/span&gt;
sudo mkdir /data/db
&lt;span class="c"&gt;# change ownership for the directory and start the mongo server&lt;/span&gt;
sudo chown your_username /data/db
mongod
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Boom. After this you can just &lt;code&gt;mongoimport&lt;/code&gt; entire &lt;code&gt;.json&lt;/code&gt; files into your database as different collections or however you'd like. So all of that to say that it is definitely easier to get things set up and data into the database (not to say that SQL isn't good...they are good for different things).&lt;/p&gt;
&lt;p&gt;With the database set up, I had to get my data.&lt;/p&gt;
&lt;h3&gt;Presidential Data&lt;/h3&gt;
&lt;p&gt;There were a couple sites that had some great resources, but the one that I ended up using was the UC Santa Barbara &lt;a href="http://www.presidency.ucsb.edu/sou.php"&gt;American Presidency Project&lt;/a&gt;. It has speeches, press releases, and much more dating back to President Washington.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.presidency.ucsb.edu/sou.php"&gt;&lt;img alt="American Presidency Project" src="/images/presidency_project.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;While it would have been great to have some form of an API to make calls to and get nicely formatted data, I did not have that luxury in this case and so I scraped the data that I needed using BeautifulSoup. Usually, this wouldn't be the easiest part, but this time it was actually quite simple!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# make the request to the website&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;requester&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;    url: url of the site to be scraped&lt;/span&gt;
&lt;span class="sd"&gt;    return: BeautifulSoup obejct of the scraped text&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ok&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# state of the union addresses urls&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_union_address_url&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requester&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c"&gt;# only extract the links from the page that link to speeches&lt;/span&gt;
    &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;table&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.*/ws/index&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;speech_urls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;link&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;speech_urls&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;speech_urls&lt;/span&gt;

&lt;span class="c"&gt;# extract the text from the speeches as a dictionary&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_union_address&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requester&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;president&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;:&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;president&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;

    &lt;span class="c"&gt;# create a dictionary with the details of interest&lt;/span&gt;
    &lt;span class="n"&gt;date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strptime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;span&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;class&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;docdate&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;%B &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s"&gt;, %Y&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;span&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;class&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;displaytext&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;

    &lt;span class="c"&gt;# each paragraph is separated into (as it will be considered a document in later analyses)&lt;/span&gt;
    &lt;span class="n"&gt;text_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;text_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;text_list&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;aDict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;president&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;president&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;text_list&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;url&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;speech&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;State of the Union&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;aDict&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Those three functions above are a sample of the functions that I wrote to scrape the State of the Union Addresses from the website. I had similar functions to scrape Inaugural Addresses and press releases. After getting all the text, I created dictionaries with the details of the speeches and used &lt;code&gt;pymongo&lt;/code&gt; to connect to mongoDB so that I could store the data.&lt;/p&gt;
&lt;p&gt;It wasn't necessary to use mongoDB because I used Python to scrape the data and was going to manipulate the data in Python,but I wanted to learn how to use the database for future reference. Furthermore, in case anything happened I wouldn't have to rely on the pickled files I created (as an extra saftey measure...).&lt;/p&gt;
&lt;h3&gt;Network Graph&lt;/h3&gt;
&lt;p&gt;If you took a look at the HTML page that I linked to at the beginning with the network graph of the presidents, you'll notice that there are clusters of presidents. Initially, I hypothesized that the presidents would be clustered by their respective parties; however, I turned out to be really wrong! They were mostly clustered based by the period in which they were president. This makes sense and I will discuss this later.&lt;/p&gt;
&lt;p&gt;So how did I generate those clusters? Well, let me start off by talking about how I got to clustering. &lt;/p&gt;
&lt;h4&gt;Latent Semantic Indexing&lt;/h4&gt;
&lt;p&gt;One of the interesting techniques that I wanted to use was &lt;a href="https://en.wikipedia.org/wiki/Latent_semantic_indexing"&gt;latent semantic indexing&lt;/a&gt;. Very basically, this technique uses matrix factorization (singular value decomposition) to map the documents into a vector space, then we specify the rank (kind of like the number of concepts that we want to keep). Afterwards, the passed in term frequency matrix is factorized into a term concept matrix, a square singular value matrix, and a concept document matrix. The concept document matrix can be thought of as a matrix that captures the latent 'concepts' within the documents.&lt;/p&gt;
&lt;p&gt;I used the concept document matrix and computed the cosine similarity between each of the different vectors (in this case each president had his own vector that signified the concepts in his speeches and press releases). Then I created the connections by simply setting the threshold to &amp;gt;= 0.75 (I experimented with this for a bit to see how the connections would turn out; a bit arbitrary, but if I had more time I would have kept all connections and used the weight/width of the connection to represent the cosine similarity).&lt;/p&gt;
&lt;h3&gt;Taking a Step Back&lt;/h3&gt;
&lt;p&gt;With the network created, I realized that the connections were actually based more on the time period in which the presidents served. So I added the color and labels to identify the presidents by the period in which they served. I also included the party toggle to show that my initial hypothesis was incorrect.&lt;/p&gt;
&lt;p&gt;In order to learn more about what the presidents' talked about, I decided to dive down into the particular time periods. My thought was that if I could limit the president set to within the same time period, then some of the finer details of topics discussed would show up.&lt;/p&gt;
&lt;h4&gt;Latent Dirichlet Allocation&lt;/h4&gt;
&lt;p&gt;&lt;a href="/html/president.html"&gt;&lt;img alt="LDA Topics" src="/images/lda_bubbles.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In order to extract the topics that were discussed in the different speeches and press releases, I decided that it would be more accurate to run the analyses on separate paragraphs. When a president gives a State of the Union Address or Inaugural Address, each paragraph is typically a separate topic; therefore, I made each paragraph an individual document (if it was more than 10 words long).&lt;/p&gt;
&lt;p&gt;I used &lt;a href="http://jmlr.csail.mit.edu/papers/v3/blei03a.html"&gt;latent dirichlet allocation&lt;/a&gt;, which is a probabilistic approach to generating topics. Very basically, we start by randomly assigning k topics to a document (a mixture of topics), then each word in the document to a topic. This is a fairly poor representation of the topics at this stage, but it improves by going through and updating the topic for each word by choosing a new topic with probability that the new topic generated this word (here is an &lt;a href="https://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation/answer/Edwin-Chen-1?srid=CiUY"&gt;awesome explanation&lt;/a&gt; that is a lot more clear! Go read! seriously!).&lt;/p&gt;
&lt;p&gt;Therefore, for each paragraph I extracted the most likely topic words (from the LDA output). Just to finish things up, I connected these topic words back to the initial paragraphs so that I could see the paragraphs that LDA determined to be a certain topic.&lt;/p&gt;
&lt;h3&gt;Summary&lt;/h3&gt;
&lt;p&gt;This project took quite a bit of coordination and also learning because I was trying to use different technologies that I didn't have much experience with. However, it was one of the most fulfilling projects, because by the end I had something that not only summarized the analyses that I performed, but also an interactive demonstration so that others could explore as well.&lt;/p&gt;
&lt;p&gt;With that said, there are definitely improvements to be made.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It isn't long before you notice that some of the initial paragraphs in the scrolling text box are not paragraphs. Instead, there are headers, questions, and other irrelevant forms of text. These should be taken out because they do not really represent paragraphs that the presidents spoke&lt;/li&gt;
&lt;li&gt;As an additional analyses, it would be interesting to run LDA on speeches that aren't State of the Union or Inaugural Addresses because these speeches are typically very broad ranging in topics discussed and therefore each president in the same period of time would most likely be discussing similar matters (think Obama and Bush talking about war...)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Anyways, those are just a few that came to mind. I hope you enjoyed the post and the visualizations!&lt;/p&gt;</summary></entry><entry><title>Making Census Data Exciting (Part 2)</title><link href="http://jeffwen.github.io/2016/03/18/making_census_data_exciting_part_2" rel="alternate"></link><updated>2016-03-18T17:47:00-07:00</updated><author><name>Jeff Wen</name></author><id>tag:jeffwen.github.io,2016-03-18:2016/03/18/making_census_data_exciting_part_2</id><summary type="html">&lt;p&gt;&lt;em&gt;March 18, 2016&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In this post, I discuss the results of the work from the &lt;a href="/2016/02/27/making_census_data_exciting_part_1"&gt;first post&lt;/a&gt;. That first post was a bit lengthy and went into the details of getting the PostgreSQL set up, but that was all necessary to be able to query the data to set up the &lt;a href="/html/dashboard.html"&gt;dashboard&lt;/a&gt; (a screenshot is shown below, you can click on multiple things at once...cross filter charts)!&lt;/p&gt;
&lt;p&gt;&lt;a href="/html/dashboard.html"&gt;&lt;img alt="Dashboard" src="/images/dashboard.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Problem Statement&lt;/h3&gt;
&lt;p&gt;So the goal of the project was to see if &lt;a href="https://archive.ics.uci.edu/ml/datasets/Census+Income"&gt;census data&lt;/a&gt; could be used in an interesting manner. While discussing possible problems that could be solved, our team figured that it would be interesting to use the data as if we had just acquired a freelance employment company. Let me make this more clear:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The parent company (a job posting company, think Monster.com), had just acquired a freelance job posting company (they have many freelance, gig type job postings)&lt;/li&gt;
&lt;li&gt;The parent company has a database of existing users but because it was not focused on freelance and gig type jobs, the database does not have hours worked per week as a feature for its users&lt;/li&gt;
&lt;li&gt;Machine learning would be used to predict how many hours an individual works (we bucketed this into &amp;lt; 40 hours or &amp;gt;= 40 hours)&lt;/li&gt;
&lt;li&gt;Ultimately, in the hypothetical world, we would then target individuals that (we predicted) worked &amp;lt; 40 hours with the part-time job postings (from the acquired company)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After the prediction, was the visualization aspect that would help our hypothetical company's managers to slice and dice data as they wanted.&lt;/p&gt;
&lt;h3&gt;Approach&lt;/h3&gt;
&lt;p&gt;As part of the problem, I wanted to use PostgreSQL to get used to using it in a remote environment so that I could learn to store my data remotely (hence the previous post). However, the next step was to get the data out of the database so that it could be manipulated and massaged for further analysis.&lt;/p&gt;
&lt;p&gt;For this, Psycopg2 was the best tool as it allowed for a pretty straight forward way to connect with the remote database. I wrote a Python script so that anyone on my team could quickly enter their login details and the script would ask for the SQL query. Then, the output would be a pandas dataframe of the data that was requested.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# input must be strings&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;query_database&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dbname&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;    dbname: database name&lt;/span&gt;
&lt;span class="sd"&gt;    user: username&lt;/span&gt;
&lt;span class="sd"&gt;    password: password for the user&lt;/span&gt;
&lt;span class="sd"&gt;    host: public dns&lt;/span&gt;
&lt;span class="sd"&gt;    port: typically for postgresql 5432&lt;/span&gt;
&lt;span class="sd"&gt;    returns a pandas dataframe of the given query&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c"&gt;# Create connection with database&lt;/span&gt;
        &lt;span class="n"&gt;conn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;psycopg2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dbname=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;dbname&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot; user=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot; password=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot; host=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot; port=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Connected&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;cur&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

        &lt;span class="c"&gt;# Ask for user&amp;#39;s SQL query&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Query please: &amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;input_query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;raw_input&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

        &lt;span class="c"&gt;# Execute search query&lt;/span&gt;
        &lt;span class="n"&gt;cur&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_query&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cur&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fetchall&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

        &lt;span class="c"&gt;# Return dataframe&lt;/span&gt;
        &lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;cur&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;

    &lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Connection error or query mistake&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This made it quite easy to get the data out of the AWS database. The next steps was to clean the data and then run models to predict the hours worked.&lt;/p&gt;
&lt;p&gt;In terms of cleaning the data, I wrote a function that took as input the previously outputted dataframe and returned a cleaned dataframe with white spaces removed from column headers, hours per week worked turned into a binary variable (&amp;lt; 40 hours worked or &amp;gt;= 40 hours worked), and other categorical variables turned into dummy variable columns. &lt;/p&gt;
&lt;h3&gt;Predictions&lt;/h3&gt;
&lt;p&gt;For the next step, we used the cleaned data as input to a couple different classification models. In order to test our models' accuracy we used 3 fold cross validation and achieved an accuracy score of ~70%. We could have used other error metrics but in our case we felt like the model was performing as good as we would have expected (we actually averaged couple models to achieve this accuracy).&lt;/p&gt;
&lt;p&gt;Given the business problem, we were okay with 70% because for our hypothetical company, any classification of &amp;lt; 40 hours worked (part-time) would mean that those individuals now had a lot of new job postings to browse (we acquired a freelance/ gig job posting company). Therefore, any exposure to these job postings would be better than nothing at all. Of course, in reality as we begin to get responses to the part-time job postings we would refine the prediction to make sure that we aren't showing part-time jobs to individuals who are actually working full-time (false positives).&lt;/p&gt;
&lt;h3&gt;Dashboard&lt;/h3&gt;
&lt;p&gt;The dashboard. Oh man. Okay, so a big part of this project was to practice using D3. Honestly, I had seen D3 used before, but I had no idea how flexible it was and how cool it was (the ease of use is something else). So I was quite excited to get my hands dirty.&lt;/p&gt;
&lt;p&gt;The great thing about making dashboards is that there are lots of examples to draw from. For this particular dashboard, I used an example that &lt;a href="http://bl.ocks.org/saraquigley/81807cb241cb4bbbaa6b"&gt;Sara Quigley&lt;/a&gt; had made.&lt;/p&gt;
&lt;p&gt;By the end, the resulting dashboard was quite different and I felt like I got to experiment with quite a lot of different techniques. &lt;em&gt;(as an aside: I am thankful for templates and also think that if possible you should make use of resources that are available, but make sure you know what is actually happening when you change things!)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I spent a lot of time reading through the code to try to understand how cross filter objects were being created and used. By the end, I had taken out a couple charts and also added a few items to the dashboard so that it fit out business problem&lt;/p&gt;
&lt;p&gt;Also reading &lt;a href="https://github.com/mbostock/d3/wiki/API-Reference"&gt;documentation&lt;/a&gt; is probably one of the best ways to learn so I did a lot of that.&lt;/p&gt;
&lt;h3&gt;Summary&lt;/h3&gt;
&lt;p&gt;Overall, this project was quite interesting in that it had multiple moving parts that came together as a single dashboard deliverable. The awesome thing about this project was that it was pretty open ended so the problem statement that we came up with actually seemed like a real problem.&lt;/p&gt;
&lt;p&gt;I spent most of my time on setting up the database, writing the script to pull data out, and tweaking/customizing the dashboard. In terms of takeaways, I realized that visualization is a large aspect of data science because the communication of results is vital to any problem. More specifically, a visually appealing tool can really help tell an impactful story (of course, the tool has to make sense).&lt;/p&gt;
&lt;p&gt;Working with PostgreSQL and D3 helped me understand a more complete picture of the analytics space than just using Python. Moving forward, I would like to continue expanding my knowledge in these technologies and more!&lt;/p&gt;</summary></entry><entry><title>Making Census Data Exciting (Part 1)</title><link href="http://jeffwen.github.io/2016/02/27/making_census_data_exciting_part_1" rel="alternate"></link><updated>2016-02-27T13:31:00-08:00</updated><author><name>Jeff Wen</name></author><id>tag:jeffwen.github.io,2016-02-27:2016/02/27/making_census_data_exciting_part_1</id><summary type="html">&lt;p&gt;&lt;em&gt;February 27, 2016&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Let's talk about remote servers, census data, classification models, and data visualization...lots to cover...&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Warning:&lt;/em&gt; This post will be a bit lengthy and cover some details that might not be that interesting but I am also using this post as a way to capture the process so I don't forget things.
&lt;img alt="Census Logo" src="/images/census-logo.png" /&gt;&lt;/p&gt;
&lt;h3&gt;Summary&lt;/h3&gt;
&lt;p&gt;In this post, I will discuss some of the design decisions that I made while working on this project and also go through some of the set up required to get things up and running. To start off with the goal of this project was to take census data and use it and visualize it in an interesting way.&lt;/p&gt;
&lt;p&gt;While I did not really have a clear idea when I started the project, I worked with a couple of my teammates to come up with an overall plan. We had to use &lt;a href="https://archive.ics.uci.edu/ml/datasets/Census+Income"&gt;census data&lt;/a&gt; and also had to think about how to tell a story with that data using classification models and D3.js. With this said, we really racked our brains to try to figure out how to use the data in an interesting way. I think we eventually did and will share more in the upcoming 2 posts!&lt;/p&gt;
&lt;h3&gt;Setup&lt;/h3&gt;
&lt;p&gt;One of the tools that I wanted to start playing around with was Amazon's EC2 servers because the trial version is free for the first year and I also wanted to learn the technology! However, the set up for the EC2 server was actually not as straight forward as I would have imagined. Particularly because I wanted to use PostgreSQL and directly connect to the server to pull data into my local machine to analyze with Python (Psycopg2 to the rescue).&lt;/p&gt;
&lt;h4&gt;Amazon Instance&lt;/h4&gt;
&lt;p&gt;Anyways, the first step was to create the EC2 instance:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Make sure that you have an AWS account and select a region that makes sense (in my case US West)&lt;/li&gt;
&lt;li&gt;Choose one of the configurations that you want (my teammates and I chose Ubuntu)&lt;/li&gt;
&lt;li&gt;Select a "free tier" instance ("t2.micro" for me!)&lt;/li&gt;
&lt;li&gt;Walk through the setup process by following the prompts&lt;/li&gt;
&lt;li&gt;Setup security groups&lt;ul&gt;
&lt;li&gt;This part was a bit confusing because PostgreSQL required another port to allow connections from my local machine's Python (will talk more about this later)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Choose to "Create a new key pair" and give it a name&lt;/li&gt;
&lt;li&gt;Download your .pem file.&lt;/li&gt;
&lt;li&gt;Move the file somewhere sensible like ~/.ssh/.&lt;/li&gt;
&lt;li&gt;Make the file read only with chmod 400 filename&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point, the server is set up and can be accessed using:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ssh -i ~/.ssh/my_cool_machine.pem ubuntu@123.234.123.234
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;Loading the tools and getting things ready&lt;/h4&gt;
&lt;p&gt;At this point we needed to get a couple packages onto the server so that we could get working. &lt;code&gt;apt-get&lt;/code&gt; is awesome for this when using Ubuntu.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;First of all we needed to be able to install Python related things:&lt;ul&gt;
&lt;li&gt;Use &lt;code&gt;pip&lt;/code&gt; to install Python things: &lt;code&gt;sudo apt-get install python-pip&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Other scipy things: &lt;code&gt;sudo apt-get install python-numpy python-scipy python-matplotlib ipython ipython-notebook python-pandas python-sympy python-nose&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;I like git and emacs :) : &lt;code&gt;sudo apt-get install git emacs&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Instead of signing in as 'Ubuntu' I added myself as a user:&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sudo adduser [username]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Grant total access: &lt;code&gt;sudo visudo&lt;/code&gt; which will open a nano text file&lt;ul&gt;
&lt;li&gt;Add &lt;code&gt;[username] ALL=(ALL:ALL) ALL&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Setup public key by following this &lt;a href="http://docs.oracle.com/cd/E19253-01/816-4557/sshuser-33/index.html"&gt;link&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Once the public key is generated copy it/ paste it onto remote server (copy/ paste probably isn't the best way... but it works!)&lt;ul&gt;
&lt;li&gt;Copy this &lt;code&gt;~/.ssh/id_rsa.pub&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Create proper files on remote machine &lt;code&gt;sudo mkdir /home/my_cool_username/.ssh/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Paste the copied public key into the authorized keys file &lt;code&gt;sudo nano /home/my_cool_username/.ssh/authorized_keys&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;This should work now! &lt;code&gt;ssh my_cool_username@123.234.123.234&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Make it easier to login&lt;ul&gt;
&lt;li&gt;Edit ssh config file by adding&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Host my_cool_machine&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;User my_cool_username&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Edit &lt;code&gt;/etc/hosts&lt;/code&gt; file&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Host_ip my_cool_machine&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Finally we can now login using &lt;code&gt;ssh my_cool_machine&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;And easily move things over to the remote machine using &lt;code&gt;scp cool_file.png my_cool_machine:~&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;PostgreSQL&lt;/h4&gt;
&lt;p&gt;In order to start using PostgreSQL I had to install PostgreSQL onto the remote machine and set up the access so that I could reach it from my local machine through Python.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install PostgreSQL &lt;code&gt;sudo apt-get install postgresql postgresql-contrib&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start and stop the PostgreSQL server using the following&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sudo service postgresql status&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sudo service postgresql stop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sudo service postgresql start&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Installing PostgreSQL created a &lt;code&gt;postgres&lt;/code&gt; user, but to add myself as a user I had to&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo -u postgres createuser --superuser my_user_name
sudo -u postgres psql
&lt;span class="c"&gt;# now in psql...&lt;/span&gt;
&lt;span class="se"&gt;\p&lt;/span&gt;assword my_user_name
&lt;span class="c"&gt;# exit out of psql with Ctrl+D&lt;/span&gt;
&lt;span class="c"&gt;# Create a database for your user&lt;/span&gt;
sudo -u postgres createdb my_user_name
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Load the data&lt;/h3&gt;
&lt;p&gt;At this point the Postgres environment was set up but there was no data yet! So in order to add some data, I found it easiest to just directly import a &lt;code&gt;.csv&lt;/code&gt; file. However, I had to create the database first.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;CREATE&lt;/span&gt; &lt;span class="k"&gt;DATABASE&lt;/span&gt; &lt;span class="n"&gt;census&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then switch to the newly created database &lt;code&gt;\c endor&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;CREATE&lt;/span&gt; &lt;span class="k"&gt;TABLE&lt;/span&gt; &lt;span class="n"&gt;census&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="nb"&gt;SERIAL&lt;/span&gt; &lt;span class="k"&gt;PRIMARY&lt;/span&gt; &lt;span class="k"&gt;KEY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; 
    &lt;span class="n"&gt;workclass&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;fnlwgt&lt;/span&gt; &lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;education&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;education_num&lt;/span&gt; &lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;marital_status&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;occupation&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;relationship&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;race&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;sex&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;capital_gain&lt;/span&gt; &lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;capital_loss&lt;/span&gt; &lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;hours_per_week&lt;/span&gt; &lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;native_country&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt;
&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now with the data table set up, I scp'ed the census data from my local machine to the remote machine and copied the data into database.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;COPY&lt;/span&gt; &lt;span class="n"&gt;census&lt;/span&gt; &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/path/to/ewoks.csv&amp;#39;&lt;/span&gt; &lt;span class="k"&gt;DELIMITER&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;,&amp;#39;&lt;/span&gt; &lt;span class="n"&gt;CSV&lt;/span&gt; &lt;span class="n"&gt;HEADER&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Permissions&lt;/h3&gt;
&lt;p&gt;Now the Postgres database is set up and work can begin if I wanted to do all the work on my remote machine. However, it is much easier to work from my local machine so I had to change a few things in the Postgres configuration files and my Amazon AWS security group.&lt;/p&gt;
&lt;p&gt;Lets start with the AWS security group. Whenever I want to log into my remote machine from a different IP address I need to add a 'rule' that allows that new IP address (or I can set it to allow any IP but thats probably not the best). So under security group on my AWS I add a new SSH with my current IP address. But I also need to allow communication with the Postgres database. Luckily, AWS has a pretty smooth process for this. Once again I add a 'rule' but this time from the drop down I select 'PostgreSQL' and I can allow any IP address to access the databse or some specified ones.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Postgres AWS" src="/images/postgre_aws.png" /&gt;&lt;/p&gt;
&lt;p&gt;In order to edit the Postgres configuration files, I need to go back into my remote machine. There are 2 files that I need to edit.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sudo nano /etc/postgresql/9.3/main/postgresql.conf&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;Under 'CONNECTIONS &amp;amp; AUTHENTIFICATION' change the 'listening_addresses' from 'localhost' to '*' this will allow all to access&lt;ul&gt;
&lt;li&gt;&lt;code&gt;listen_addresses = '*'&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sudo nano /etc/postgresql/9.3/main/pg_hba.conf&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;Under 'IPv4 LOCAL CONNECTIONS' I change the allowed IPs&lt;ul&gt;
&lt;li&gt;&lt;code&gt;host all all 0.0.0.0/0 trust&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;FINALLY. At this point, I can actually access my remote database from my local machine. However, when using Python and psycopg2 to access the database there were a few more hurdles that I had to jump over :(.&lt;/p&gt;
&lt;h3&gt;Psycopg2 and Python&lt;/h3&gt;
&lt;p&gt;To directly connect with the database I had to install &lt;a href="http://initd.org/psycopg/"&gt;psycopg2&lt;/a&gt;, which is a Postgres adapter for Python. I did the following in order to get the set up working... (lots of steps and troubleshooting; took  me a long time to figure out the last step)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;brew&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;postgresql&lt;/span&gt;
&lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;psycopg2&lt;/span&gt;
&lt;span class="c"&gt;# this next step I had to preform only because it kept throwing back an error saying that my&lt;/span&gt;
&lt;span class="c"&gt;# AWS was not set up correctly but when I looked on stackoverflow it seemed like it was a psychopg2 bug&lt;/span&gt;
&lt;span class="n"&gt;brew&lt;/span&gt; &lt;span class="n"&gt;unlink&lt;/span&gt; &lt;span class="n"&gt;openssl&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;brew&lt;/span&gt; &lt;span class="n"&gt;link&lt;/span&gt; &lt;span class="n"&gt;openssl&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;force&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Finishing up&lt;/h3&gt;
&lt;p&gt;Whew! That was exciting. I know...&lt;/p&gt;
&lt;p&gt;The process to get the server and database all set up may seem quite tedious, but many of the steps above are actually quite quick! Plus, it is good to have things all set up so that the analysis and visualization steps can happen smoothly! In the next post, I will discuss more of the details behind the analysis and also hopefully show a working version of the D3 dashboard!&lt;/p&gt;</summary></entry><entry><title>Movie Scraping and Regression Analysis</title><link href="http://jeffwen.github.io/2016/02/10/movie_scraping_and_regression_analysis" rel="alternate"></link><updated>2016-02-10T16:27:00-08:00</updated><author><name>Jeff Wen</name></author><id>tag:jeffwen.github.io,2016-02-10:2016/02/10/movie_scraping_and_regression_analysis</id><summary type="html">&lt;p&gt;&lt;em&gt;February 10, 2016&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In ths post, I will share a bit about what I have been up to over the past few weeks. I plan on putting up my code soon!&lt;/p&gt;
&lt;h1&gt;Getting Started&lt;/h1&gt;
&lt;p&gt;For this project, I wanted to make use of a couple things that I learned at Metis. More specifically, I was interested in using BeautifulSoup, Statsmodels, and Scikit-learn to try and predict total adjusted domestic gross from movie data scraped from &lt;a href="http://www.boxofficemojo.com"&gt;boxofficemojo&lt;/a&gt;. One of the main objectives of the project was to try and get a sense for how to collect data and make sure that it is in a clean enough format to run analyses on.&lt;/p&gt;
&lt;p&gt;One of the things that I realized while participating in kaggle competitions is that a lot of the time the data comes in very nice formats. Most of the major data errors are already taken care of and there isn't much if any scraping that needs to be done to get the data (I can just download the data). Therefore, I figured it would be nice to get a sense for how to web scrape then clean the data myself to understand the process more completely.&lt;/p&gt;
&lt;h1&gt;Objectives&lt;/h1&gt;
&lt;p&gt;Below are some of the objectives that I had in mind before starting the project:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Get familiar with using BeautifulSoup to scrape web data&lt;ul&gt;
&lt;li&gt;Put HTML knowledge to use so that I can effectively isolate and extract the information I want from boxofficemojo&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compare and contrast using Statsmodels and Scikit-learn to do linear regression&lt;ul&gt;
&lt;li&gt;Understand how and when to use transformations to variables in order to create a better model&lt;/li&gt;
&lt;li&gt;Experiment between Lasso, Ridge, and Elastic Net to regularize the models that are built&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learn more about utilizing cross validation as a tool to identify the best model&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Scraping the Data&lt;/h1&gt;
&lt;p&gt;The data scraping was one of the most time consuming parts of this project because it took quite a bit of time to define the business problem enough to come up with an idea of what I needed and it was also difficult at times to navigate through the nested tables (the HTML). However, BeautifulSoup made it quite simple to grab the HTML and parse through it.&lt;/p&gt;
&lt;p&gt;More about the business problem. In order to make the project more interesting our instructors at Metis had us come up with a problem that we wanted to solve. For me, I figured I could use this the data and the model that I created to predict the total adjusted domestic gross. The motivating question for this is as a hypothetical merchandise production company (Nexus), we had already purchased rights from a couple movie studios to produce products for their movies. However, because production lines are relatively inflexible and take a while to reorganize, the business question was whether we could use a regression model to identify movies that would be more popular so that we could reorganize our production lines before crunch time (when the movies got immensely popular) to ensure that we properly allocated our resources. &lt;/p&gt;
&lt;p&gt;With this problem in mind, it was time to start the scraping process. I decided to start by scraping as many movies as possible so that I could build out my training data set. When I looked at the a &lt;a href="http://www.boxofficemojo.com/movies/?page=main&amp;amp;adjust_mo=&amp;amp;adjust_yr=2016&amp;amp;id=avatar.htm"&gt;sample page&lt;/a&gt; on boxofficemojo, I noticed that a lot of interesting information was captured in the table at the top of each movie page. As a first step, I realized it would be quick to just take down this information.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Avatar Sample" src="/images/avatar_sample.png" /&gt;&lt;/p&gt;
&lt;p&gt;I wrote a couple functions that used BeautifulSoup to output the HTML, then parse the HTML to extract just the information in that table. Afterwards, I stored the information in a dictionary of dictionaries (key = movie slug; values = information in the table) then I put that information into a pandas dataframe. The dict within a dict allowed me to add details to the dictionary for each movie if I decided to get more information (which I did).&lt;/p&gt;
&lt;p&gt;I realized that if I really wanted to create a suitable training set then I needed to scrape many movies. In order to do this, I went to the alphabetical index and scraped the links of each movie (~16k) and passed each link into the previous information getting function. After these two steps, I had most of the information that I needed.&lt;/p&gt;
&lt;p&gt;The last bit of scraping I did was to get the daily sales information and the daily theater count information. Originally I figured it would be interesting to do time series analysis on the daily sales information to predict a movie's sales and while I did try an ARIMA model I decided I would go back to that later.&lt;/p&gt;
&lt;h1&gt;Data Cleaning&lt;/h1&gt;
&lt;p&gt;The next focus was to clean the data and start thinking about how to get the model up and running. I started by importing the dataframes that I had created into my Python environment.&lt;/p&gt;
&lt;p&gt;Then I  worked with the variables to make sure that they were able to be processed&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Turning the date strings into datetime objects&lt;/li&gt;
&lt;li&gt;Turning the runtime string from "1 hr. 52 min." to integer format&lt;/li&gt;
&lt;li&gt;Getting the Month, Year, and Day for each datetime object&lt;/li&gt;
&lt;li&gt;Drop the NA values&lt;/li&gt;
&lt;li&gt;Reorder the columns&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With the initial data cleaning steps completed, I moved forward to building the linear regression models.&lt;/p&gt;
&lt;h2&gt;Model Building&lt;/h2&gt;
&lt;p&gt;I wanted to create an initial plot to take a look at some of the data and make sure that things looked normal. I also created a residual plot just to check and see if the residuals were more or less random.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;From the initial plot it looks like there are quite a few values that are sitting right at 0, so I want to look and see what those are/ get rid of the ones that are NAs (though we should have already dropped these)&lt;ul&gt;
&lt;li&gt;When I looked further into this problem, it seemed like the problem was not from NAs but actually from opening sales that were exteremly small&lt;/li&gt;
&lt;li&gt;Further investigation showed that the very small observations were from releases at very few theaters vs. many theaters&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The residuals plot also looks a bit bunched together and definitely looks like there is some heteroscedasticity&lt;/li&gt;
&lt;li&gt;I decided that it might be good to transform the data to see if it could deal with some of the effect&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Initial Residuals" src="/images/initial_resids.png" /&gt;&lt;/p&gt;
&lt;p&gt;After fitting the initial model, the adjusted R-squared was .457, which was not too horrible for a first go. I continued the process of analyzing the shape of the residuals and further transformed variables that seemed to have non-normal residuals. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Inital Regression Results" src="/images/initial_reg.png" /&gt;&lt;/p&gt;
&lt;h3&gt;Bring in more data&lt;/h3&gt;
&lt;p&gt;In order to deal with the observations that looked to bunched near 0, I brought in the number of theaters that the movie was released at to calculate the average opening sales per number of theaters.&lt;/p&gt;
&lt;h3&gt;Continuing the model building&lt;/h3&gt;
&lt;p&gt;With the new data, I continued to iterate and build models successively by tuning the parameters (mainly by plotting the residuals and looking to see if the residuals were random/ checking to see that there weren't major collinearity problems). By this time the model's adjusted R-squared was at .657.&lt;/p&gt;
&lt;p&gt;I figured it might be good to group the genres because some of the genres were occurring realtively infrequently. So I wrote a function to standardize the number of genres. However, when I ran the regression again, the model seemed to fit the data less well so I took out the new genre variable that I created.&lt;/p&gt;
&lt;p&gt;After performing log and exponential transformations to the dependent and some of the independent variables, the model seemed to be more or less set (at least in terms of fit of the residuals and the adjusted r-squared ~0.70). &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;model4&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;smf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ols&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;exponential(Adjusted_Gross,0.1) ~ exponential(Avg_per_Theater, 0.3) + Genre + Popular_Month + exponential(Runtime, 0.5)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model_data_3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;result4&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model4&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_regularized&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In the above code example, the &lt;code&gt;Popular_Month&lt;/code&gt; independent variable is a generated binary variable based on which of the months were popular (May, June, July, November, and December).&lt;/p&gt;
&lt;p&gt;Given that the model was explaning about ~30% more of the variance than the initial model, I felt like it was time to move to scikit-learn to do some train test splits along with cross validation to make sure that the model was performing as expected on unseen data. &lt;/p&gt;
&lt;h2&gt;Move to scikit-learn&lt;/h2&gt;
&lt;p&gt;The main reason for moving to scikit-learn at this point was to take advantage of the convenient cross validation tools.&lt;/p&gt;
&lt;p&gt;The move to scikit-learn meant that I needed to make sure that the features were properly processed so that sklearn could take it all in. Unlike statsmodels, dummy variables are not automatically generated in sklearn so it is actually easier to generate the dummy variables using pandas.get_dummies() function. However, I made sure to delete one of the columns from each column that I was turning into dummy variables so there would not be collinearity issues.&lt;/p&gt;
&lt;p&gt;Another benefit of using scikit-learn is that the &lt;a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model"&gt;regularized linear models&lt;/a&gt; are accessible and quite easy to use. I experimented with lasso, ridge, and eventually decided to use elasticnet because it makes use of both lasso and ridge regularization. (Also scikit-learn bundles cross validation and elasticnet which makes scoring and testing the models quite simple!)&lt;/p&gt;
&lt;p&gt;In order to do cross validation, I used sklearn's &lt;code&gt;train_test_split&lt;/code&gt; module to create 70%/30% splits of the ~900 or so observations. Then I trained the model on the 70% and performed 10-fold ElasticNetCV (with sklearn) and separately tested on the remaining 30%.&lt;/p&gt;
&lt;h1&gt;What Did I Learn&lt;/h1&gt;
&lt;p&gt;Throughout the process, I realized that I was going back and forth between many of the different models and features to figure out what combination worked the best. While I could probably have used grid search or something similar to find the best parameters and automatically build a model, it was fun to manually work through building the model step by step.&lt;/p&gt;
&lt;p&gt;I also learned how to use BeautifulSoup to scrape data from a web page. While BeautifulSoup is a great package, I learned that it was still quite time consuming to figure out where the data actually resides.&lt;/p&gt;
&lt;h1&gt;Next Steps&lt;/h1&gt;
&lt;p&gt;Given that this project encapsulated many different aspects, I think that the main improvements and ways to continue learning is to refine each of the steps. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Web scraping: I used BeautifulSoup to scrape the web page, but I want to think about using Selenium to scrape web pages that might not have nicely laid out HTML (think information kidden behind a more interactive dynamic javascript page).&lt;/li&gt;
&lt;li&gt;Modeling: most of the modeling building and analyses that I performed in statsmodels and sklearn had to do with linear regression. However, there were many different features of both packages that I didn't get a chance to look at. I think it would be interesting to continue utilizing both packages for futher analyses.&lt;ul&gt;
&lt;li&gt;statsmodels: I performed some initial trend and seasonal decomposition in order to do time series analysis (see detrended and deseasoned graphs below!) but as mentioned earlier I decided against further looking into this for the time being.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Seasonal Decomposition" src="/images/seasonal_decompose.png" /&gt;&lt;/p&gt;
&lt;p&gt;This was a fun project that exposed me to a lot of different tools and I look forward to learning more by continuing some of the ideas that I had about how to extend the analysis!&lt;/p&gt;</summary></entry><entry><title>What's Cooking?</title><link href="http://jeffwen.github.io/2015/12/19/whats_cooking" rel="alternate"></link><updated>2015-12-19T11:01:00-08:00</updated><author><name>Jeff Wen</name></author><id>tag:jeffwen.github.io,2015-12-19:2015/12/19/whats_cooking</id><summary type="html">&lt;p&gt;&lt;em&gt;December 19, 2015&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Update!&lt;/strong&gt;: The competition has now ended and I am in 87th place on the public leaderboard out of 1,388 teams/individuals. Top 6% for my first kaggle!&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;Getting Started&lt;/h3&gt;
&lt;p&gt;Ever since I have known about kaggle, I have always seen it as a place where accomplished data scientists and skilled veterans of the machine learning space go to stretch their legs and dominate. However, as I continued to look through the competitions and through the forums where aspiring data scientists were asking a wide variety of questions, I realized that my preconceptions were probably holding me back from learning a lot through practical application. It is definitely one thing to read about algorithms and techniques and quite another to actually implement. Anyways, with that in mind, I figured I would jump in and get started.&lt;/p&gt;
&lt;p&gt;Before I got started on the whats cooking competition, I had read a lot about the models that I was planning to use and had also read code from past competitions; however, jumping into the competition helped me actually get my hands dirty with models that I had only used a couple times before. More importantly, having to actually write the code myself, I got to practice being (or at least trying to be) systematic and comprehensive in my modeling decisions. Ultimately, I think the competition pushed me to not only read/learn, but also practice and be comfortable with an iterative problem solving process. &lt;/p&gt;
&lt;h3&gt;What's Cooking&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://www.kaggle.com/c/whats-cooking"&gt;competition&lt;/a&gt; as mentioned before was hosted on the kaggle platform. While there were many competitions to choose from, I decided to do this cooking challenge because I was interested in learning natural language processing, which I felt like I hadn't really been able to practice. Although the competition did not require much real language processing, it was still appealing and interesting to think about how different ingredients could be used to predict the cuisine. &lt;em&gt;(Most of the code for this competition is on my &lt;a href="https://github.com/jeffwen/Kaggle/blob/master/Whats%20Cooking/cooking.py"&gt;github&lt;/a&gt;. There are a few cleanup functions and exploratory scripts that I unfortunately have on another computer)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For me, the largest reason for joining this competition was to learn. More than wanting to place well on the leaderboard, I wanted to understand what I was doing with the algorithms I was using and I wanted to make educated decisions about my modeling choices. &lt;em&gt;Then&lt;/em&gt;, if I happened to do well that would be an additional blessing. As a result, I spent lots of time learning by reading and tinkering. Instead of copying code from forums, I wanted to implement things myself, which took lots of time...lots of trial...and lots of error...&lt;/p&gt;
&lt;h4&gt;&lt;em&gt;Initial decisions&lt;/em&gt;&lt;/h4&gt;
&lt;p&gt;To start with, my plan was to (I eventually only had time to do up to number 7, but ended up with a satisfying score):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Start by exploring the data and summarizing the data to understand how the classes look, how the ingredients are distributed across cuisines, and start brainstorming which models I wanted to use&lt;/li&gt;
&lt;li&gt;Process the data so that I could use it as input into the model that I had decided to move forward with&lt;/li&gt;
&lt;li&gt;Build a simple baseline model upon which I could further improve&lt;ul&gt;
&lt;li&gt;Logistic regression was good for this problem because its a simple model compared to the other models that I could have started with...&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;See if I need to change the way I was extracting features/ implement new feature extraction techniques to get more information from the data&lt;/li&gt;
&lt;li&gt;Fit the simple model again and tune the parameters&lt;/li&gt;
&lt;li&gt;Start experimenting with and tuning more complex models that make sense given the problem&lt;ul&gt;
&lt;li&gt;One thing that I am trying to learn more about is when to use a model given the input data because it is easy to throw a million models at a problem and see what works, but it takes experience and skill to figure out what model would work best given the nature of the data (though in averaging I use many random models because the point of the weighted averaging, as I know it, is to try to use weak learners and/or uncorrelated submission files to create a stronger learner/submission)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Think about simple averaging by coming up with a weighted average of my submissions to see if the model performs better&lt;/li&gt;
&lt;li&gt;Enter into the real black box stuff where I stack and blend models to build crazy ensembles&lt;ul&gt;
&lt;li&gt;Some really &lt;a href="http://mlwave.com/kaggle-ensembling-guide/"&gt;legit stuff&lt;/a&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Anyways, the data comes in .json files, which python makes pretty easy to parse with the json package. As an example, the first entry in the data file looks like this&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;cuisine&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;u&amp;#39;greek&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;id&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;10259&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s"&gt;u&amp;#39;ingredients&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;u&amp;#39;romaine lettuce&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s"&gt;u&amp;#39;black olives&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s"&gt;u&amp;#39;grape tomatoes&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s"&gt;u&amp;#39;garlic&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s"&gt;u&amp;#39;pepper&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s"&gt;u&amp;#39;purple onion&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s"&gt;u&amp;#39;seasoning&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s"&gt;u&amp;#39;garbanzo beans&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s"&gt;u&amp;#39;feta cheese crumbles&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;em&gt;Note: I did a few things to look through the data and summarize/ explore the data before I got started. Namely, I looked at the counts of the each cuisine to see if there were any biased classes, which there were, but when I set custom weighting for the classes the models didn't change much so I decided I would return to this later. Furthermore, I looked to format the data correctly because things like the registered trademark signs caused encoding problems in the input data.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Given the way the data was formatted, I wanted to separate out the cuisine as the y-variable and have the x-variables be the ingredients. This is where the initial decisions had to be made.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How was I going to do the initial processing to set up my training data to extract features from the data?&lt;ul&gt;
&lt;li&gt;I could use a simple &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer"&gt;count vectorizer&lt;/a&gt;, which converts the words in a document (or in this case recipe) into counts or...&lt;/li&gt;
&lt;li&gt;binary encoding, which (if I implemented this correctly means 0 if the ingredient is not in the recipe and 1 if it is) or...&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer"&gt;tfidf (term frequency inverse document frequency) vectorizer&lt;/a&gt; to not only count but also return the normalized count based on how many times an ingredient appears in all the recipes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Once the format of the training data was decided, how was I going to implement the vectorizer or binary encoder?&lt;ul&gt;
&lt;li&gt;This was a question I found myself asking because the standard vectorizer and encoder in sci-kit learn were slightly different than what I wanted to do.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I initially decided to write my own binary encoder because I thought that using a count vectorizer, though simple, would be throwing away information from the data. More specifically, I figured that, using the sample above, if my ingredients were ['romaine lettuce', 'black olives', 'grape tomatoes'...] and I used the stock count vectorizer then I would have the following as features ['romaine', 'lettuce', 'black', 'olives'...]. To me this was a problem because 'black olives' as one feature contained more information than 'black', 'olives' as two features.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I had decided from the beginning that I wanted to start with a bag of ingredients and not a bag of words.&lt;/li&gt;
&lt;li&gt;Though I knew that I could customize the analyzer function in the sci-kit learn package, I wanted to start with a baseline model before moving onto more complex models.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;binary_encoding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;list_of_ingredients&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;input_data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;    list_of_ingredients: a list of ingredients that has been deduplicated and represents the features (column titles of the matrix)&lt;/span&gt;
&lt;span class="sd"&gt;    input_data: the data to be converted into a feature matrix&lt;/span&gt;
&lt;span class="sd"&gt;    returns a sparse feature matrix&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;pbar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ProgressBar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="c"&gt;# progress bar to help me figure how much has been completed&lt;/span&gt;
    &lt;span class="n"&gt;aList&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;recipe&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;pbar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
        &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fromkeys&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;list_of_ingredients&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c"&gt;# creates a new dictionary with keys from list of ingredients with the initial value set to 0&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;recipe&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;list_of_ingredients&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="c"&gt;# if the ingredient is in the list of ingredients, then change value to 1&lt;/span&gt;
        &lt;span class="n"&gt;aList&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;sparse_matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scipy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sparse&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csr_matrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aList&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c"&gt;# create a sparse matrix&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;sparse_matrix&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After implementing the function above on the data, and running a simply logistic regression model on the data, I received ~0.77 on the leaderboard. Though it wasn't great it was my first submission and I was quite happy. Even through this initial phase of feature extracting, I realized that a lot of the time I spent on this competition would be on feature engineering and processing.&lt;/p&gt;
&lt;h4&gt;&lt;em&gt;Moving forward&lt;/em&gt;&lt;/h4&gt;
&lt;p&gt;With the ~0.77 in the books, I decided it was time to start tuning and adding complexity.&lt;/p&gt;
&lt;p&gt;The first thing that I did was write a preprocessing function to help me clean the input data. I decided that I wanted to stem the words so that 'olives' would become 'olive' because the plural shouldn't lead to two different ingredients. Then I also stripped the words of punctuation and other non-alphabetic characters. After this initial step, I decided it would be good to sort the words in the ingredient list so that ingredients like 'feta cheese crumbles' and 'crumble feta cheese' would be one feature and not multiple after the word stemming and ingredient sorting (may or may not have been necessary, but I figured given the way the data was structured it wouldn't hurt).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;preprocess&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;new_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;pbar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ProgressBar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="c"&gt;# Progress bar to ease the waiting&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;recipe&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;pbar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;new_recipe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;ingredient&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;recipe&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;new_ingredient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ingredient&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
                &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;[^a-zA-Z -]+&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c"&gt;# only keeping the letters, spaces, and hyphens&lt;/span&gt;
                &lt;span class="n"&gt;new_ingredient&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;wn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;morphy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;,.!:?;&amp;#39; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;,.!:?;&amp;#39; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c"&gt;# strip, stem, and append the word&lt;/span&gt;
            &lt;span class="n"&gt;new_recipe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_ingredient&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;new_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_recipe&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;new_data&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sort_ingredient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;new_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;pbar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ProgressBar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;recipe&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;pbar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;new_recipe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;ingredient&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;recipe&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;sorted_ingredient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ingredient&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
            &lt;span class="n"&gt;new_recipe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sorted_ingredient&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;new_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_recipe&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;new_data&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After this preprocessing step, I move towards using &lt;a href="https://en.wikipedia.org/wiki/Tf–idf"&gt;tf-idf&lt;/a&gt; because I figured having an indication of the frequency of a certain ingredient would provide additional information as opposed to simple binary encoding. So I used the slightly modified tf-idf vectorizer from sci-kit learn. Similar to the count vectorizer, the default analyzer seemed to split up the words of an ingredient into two words because of the way that my data was being passed in. To solve this, I wrote my own analyzer function that basically parsed the ingredient list and returned the entire ingredient (with all the words) as one feature &lt;em&gt;(think: ['romaine lettuce', 'black olives'] vs. ['romaine', 'lettuce', 'black', 'olives'])&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Ultimately, combining the preprocessing with the tf-idf vectorizing and a logistic regession model gave me ~0.778 on the leader board (an improvement!). So the next step was to figure out how to further tune the model. &lt;/p&gt;
&lt;h4&gt;&lt;em&gt;Model tuning&lt;/em&gt;&lt;/h4&gt;
&lt;p&gt;Modeling tuning seems to be an art in the machine learning world. This was where I felt out of my league because I did not have much experience. I had manually set complexity parameters before when pruning decision trees, but had not really experimented with changing the many parameters in the models I was using.&lt;/p&gt;
&lt;p&gt;So I spent lots of time reading through the forums to see what others were doing and saw that the top performers were using grid searches. I eventually ended up using a grid search to create my strongest performing single model, but initially when I was experimenting I used cross validation to manually see how changing the regularization parameter would affect my CV scores and found that with C=5 my model was scoring around ~0.782 with the CV that I was performing on my own system. When I uploaded the submission after predicting the new cuisines I got ~0.7857 so again there was an improvement (though it was not great that my own CV was returning scores that were slightly off. I probably will spend some more time figuring out how to model a more precise evaluation metric next time.)&lt;/p&gt;
&lt;p&gt;&lt;img alt="logreg tfidf score" src="/images/logreg_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;At this point in the competition there were around ~1000 or so competitors so I was in the top 50%, which was exciting considering just a few weeks ago I didn't even think I could create any worthwhile models.&lt;/p&gt;
&lt;h4&gt;&lt;em&gt;Rethinking my initial assumptions&lt;/em&gt;&lt;/h4&gt;
&lt;p&gt;Initially, I had decided not to use the standard sci-kit learn vectorizer analyzers because I felt that it would take away information from my data. However, upon further consideration, I realized that it was worth a try because with &amp;gt; 5000 features not all the features would be important anyways so why create more features by creating a bag of ingredients if a bag of words may actually help to reduce complexity a little bit.&lt;/p&gt;
&lt;p&gt;With this in mind, I rewrote my preprocessing function and started using the tf-idf vectorizer from sci-kit learn with a few parameters modified.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;preprocess_all_ingredients&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;new_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;pbar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ProgressBar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="c"&gt;# Progress bar to ease the waiting&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;recipe&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;pbar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;new_recipe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;ingredient&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;recipe&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;new_ingredient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ingredient&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
                &lt;span class="c"&gt;# using a word lemmatizer, which is related to stemming, but takes into account context also (in this case other ingredients in the recipe)&lt;/span&gt;
                &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;[^a-zA-Z]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;new_ingredient&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;WordNetLemmatizer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lemmatize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;,.!:?;&amp;#39; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;,.!:?;&amp;#39; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;new_recipe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_ingredient&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;new_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_recipe&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;new_data&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The new function is similar to the previous preprocessing function but uses a lemmatizer instead of a stemmer (&lt;a href="http://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html"&gt;read more here&lt;/a&gt;), which basically takes context into account (though lemmatization may not have much use in this case given the ingredients are separate words in a string and not a cohesive sentence).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;tfidf_vectorizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stop_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ngram_range&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;analyzer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;word&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_df&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.56&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;token_pattern&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;r&amp;#39;\w+&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;With the new preprocessing and vectorizer in place, I used a logistic regression again and got ~0.787. So there was again an improvement but at this point, I figured maybe I had come close to the extent of progress I would make with the logistic regression model. I did run a grid search over the regularization parameter and received a score of ~0.788. However, I was ready to move onto other models and thought that I would perhaps come back to logistic regressions if I were to do stacking and blending of models later on.&lt;/p&gt;
&lt;h4&gt;&lt;em&gt;Big improvements&lt;/em&gt;&lt;/h4&gt;
&lt;p&gt;The next steps in the modeling process led to huge improvements and at one point even got me to the top 3% of the leaderboard. &lt;/p&gt;
&lt;p&gt;At this time the top performers seemed to be using neural nets and xgb models (extreme gradient boosted trees). I tried xgb but my results were not great (the best xgb gave me ~0.78). &lt;/p&gt;
&lt;p&gt;With the basic preprocessing functions set, I felt like I should spend more time on reading and understanding how to tune my models. I had used support vector machines (SVM) before, but I was unsure if the model would handle the data given that my computer is old and SVMs are not known to perform particularly quickly if the dataset is too large. Given that I had thousand of features, I was afraid of the run time of using SVMs, but in the end after reading a couple resources (including &lt;a href="http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf"&gt;this one&lt;/a&gt;) I decided I would give it a try and just change to something else if necessary. Furthermore, SVMs have fewer hyperparameters to tune (so it would be easier to set up a grid search compared to say xgb or neural nets).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;param_grid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;C&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;kernel&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;linear&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]},{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;C&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;gamma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;kernel&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;rbf&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]}]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I tried both linear and non-linear kernels and a variety of regularization parameters (I tried to read a lot on how to choose the parameters to place in the grid search). After fitting the model, which took at least 8 hours, I took a look at the parameter grid, which also shows the CV scores from the 3-fold CV that was performed in the grid search and noticed that the scores were pretty varied, but some scores were &amp;gt; 0.80. Of course I was excited, but not ecstatic because I knew that my CV was not exactly in line with the Kaggle leaderboard score calculation. When I submitted, I was surpised to see that my submission received a score on the leaderboard of ~0.81044 (&lt;strong&gt;HUGE improvement for me!&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;&lt;img alt="SVM improvement" src="/images/svm_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;At this point there were ~1200 teams in the competition so my score put me somewhere in the top 3%! I was originally okay with the top 50%...but no complaints!&lt;/p&gt;
&lt;h4&gt;&lt;em&gt;Finishing touches&lt;/em&gt;&lt;/h4&gt;
&lt;p&gt;With only a couple days or so left in the competition, I didn't have much time to run additional stacked models or try tuning neural networks. However, I knew that I could squeeze a little more out of my submissions and so I spent some time researching stacking and blending of models. I had read that many recent winners had performed so well because they had implemented some form of stacking and/or blending (the netflix prize was won by an ensemble of &lt;a href="http://data-informed.com/in-awarding-prize-for-analytics-netflix-failed-to-predict-it-wouldnt-be-used/"&gt;800 different models&lt;/a&gt;). Of course, basic understanding of what each model is doing is very important and was my main goal, but at this point I felt like I could do little more.&lt;/p&gt;
&lt;p&gt;I basically ended up doing a weighted average of my top submission files (which is not stacking or blending but a precursor step). In particular, I gave my SVM 3x weight, logreg 1x, linear SVC 1x, another logreg 1x, and extra trees classifier 1x and ended up with a score of ~0.81225, which at the time placed me at 40th out of ~1300 teams.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Ensemble score" src="/images/ensemble_1.png" /&gt;&lt;/p&gt;
&lt;h3&gt;Lots to learn&lt;/h3&gt;
&lt;p&gt;It has been such a journey starting with importing the .json files to getting (at the time) 40th on the leaderboard. Even though with a few more hours to go in the competition I figure I may drop a few places, I feel like I have gained at least a taste of what it feels like to enter and apply the things that I have learned.&lt;/p&gt;
&lt;p&gt;In entering this competition I got a chance to apply a lot of things that I had read about. Furthermore, I read &lt;strong&gt;EVEN MORE&lt;/strong&gt; things that I didn't get to try out but hope to in the future. I have listed a few take-aways and things to try in the future.&lt;/p&gt;
&lt;h4&gt;&lt;em&gt;Next steps&lt;/em&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Use Levenstein distance to map similar words together (I actually have a function in my &lt;a href="https://github.com/jeffwen/Kaggle/blob/master/Whats%20Cooking/cooking.py"&gt;cooking code&lt;/a&gt; that I was going to use, but I never got around to implementing it...)&lt;/li&gt;
&lt;li&gt;Use Bayesian Optimization or Random Search to optimize parameter settings&lt;/li&gt;
&lt;li&gt;Stack and blend different models&lt;/li&gt;
&lt;li&gt;Experiment with other models (i.e. neural networks, xgb (with good parameter tuning))&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;em&gt;Take-aways&lt;/em&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Parameter tuning is very important and though grid search worked out well this time, its really computationally intensive and in another setting I might not have the luxury to perform this type of exhaustive search. I can try random search, which may be better but a very interesting thing that I read about were two packages called: Spearmint and Hyperopt, which use bayesian optimization to perform the parameter search (read this awesome &lt;a href="https://jmhessel.github.io/Bayesian-Optimization/"&gt;blog post&lt;/a&gt; or &lt;a href="http://fastml.com/optimizing-hyperparams-with-hyperopt/"&gt;this one&lt;/a&gt; to learn more about parameter tuning and bayesian optimization)&lt;/li&gt;
&lt;li&gt;Fitting models is easy, but figuring which model to use and when is difficult&lt;/li&gt;
&lt;li&gt;The need for a representative cross validation evaluation metric is very important if you want to know how your model is performing. I think this is why some teams spend quite a bit of time writing their own evaluation function that matches the competition's evaluation function because if they tell you how you will be judged why not use it!&lt;/li&gt;
&lt;li&gt;Simple models can actually perform really well when tuned properly. Given that simple models are MUCH faster to train it may be better to use a simple model if the application does not require absolute accuracy (this really depends on the problem at hand; healthcare is not an area where we want to use less accurate models just to speed up the modeling process)&lt;/li&gt;
&lt;li&gt;The entire problem solving approach has to iterative.&lt;/li&gt;
&lt;li&gt;Feature engineering and preprocessing take lots of time but are very important! I think this is where industry domain becomes handy because if I knew more about cooking I might have been able to create some more informative features&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;The End!&lt;/h3&gt;
&lt;p&gt;There are a lot of things that I have left out of this post in regards to my process and thinking but if there are any questions feel free to email me! I hope that this is just a start of my continued learning through kaggle and similar platforms. &lt;/p&gt;</summary></entry><entry><title>Setting up the blog</title><link href="http://jeffwen.github.io/2015/11/28/pelican-setup" rel="alternate"></link><updated>2015-11-28T13:03:00-08:00</updated><author><name>Jeff Wen</name></author><id>tag:jeffwen.github.io,2015-11-28:2015/11/28/pelican-setup</id><summary type="html">&lt;p&gt;&lt;em&gt;November 28, 2015&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Over the past couple of days, I have been working towards getting a blog up and running. There were a couple of different options that I was considering and ultimately I ended up choosing to use &lt;a href="http://blog.getpelican.com"&gt;Pelican&lt;/a&gt; as my site generator. I also use GitHub Pages to host my blog for free!&lt;/p&gt;
&lt;h3&gt;Decisions&lt;/h3&gt;
&lt;p&gt;Initially, I was considering just sticking with Jekyll, which is the site generator that pairs really nicely with &lt;a href="https://help.github.com/articles/using-jekyll-with-pages/"&gt;GitHub Pages&lt;/a&gt;. However, I read a couple different posts by other users, thought about the decision, and noticed the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Ruby vs. Python&lt;/em&gt;: Jekyll is Ruby based whereas Pelican is Python based.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Although I am also picking up Ruby, I am definitely more comfortable with Python at this point.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Speed&lt;/em&gt;: While I am still new to blogging and don't necessarily feel the struggle of slow page loading (given that I don't have much experience with slow loading blogs), &lt;a href="http://arunrocks.com/moving-blogs-to-pelican/"&gt;this user's&lt;/a&gt; blog post was definitely persuasive enough for me to take speed into consideration.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Personal Growth&lt;/em&gt;: Jekyll might have been easier to use given that it is integrated with GitHub so well, but I wanted to (at least in my mind at the time) learn a little bit more by using something that required just a little more work. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Getting Started&lt;/h3&gt;
&lt;p&gt;With these things in mind, I decided to jump right in and start setting up my blog. It was quite simple for the most part but it definitely took some time figuring everything out because I was trying to use a couple different resources to make sure that my blog would run smoothly. Looking back on it, I guess it probably would have been better to stick with one solid resource vs. trying to merge different ways of doing the same thing. However, as stated before, I wanted to learn as much as possible and see the different ways people were setting up their blogs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resources:&lt;ul&gt;
&lt;li&gt;&lt;a href="http://docs.getpelican.com/en/3.6.3/"&gt;Pelican Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mathamy.com/migrating-to-github-pages-using-pelican.html"&gt;Amy Halon's blog post on GitHub Pages Migration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://fedoramagazine.org/make-github-pages-blog-with-pelican/"&gt;Fedora Magazine's blog post on GitHub Pages and Pelican&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As I was following some of the resources mentioned earlier, I realized that it was a great opportunity for me to also learn more about other technologies as well. For example, I read up on GitHub submodules because Fedora's post mentioned initiaizing the output directory as a submodule. I am getting my hands dirty with Markdown because I am using Markdown to write these blog posts and pages. Additionally, HTML and CSS are relevant as well because I am learning to customize my blog. Therefore, all in all, things seem to be going pretty smoothly and I am excited to see what else I can do with this site!&lt;/p&gt;
&lt;h3&gt;Customization&lt;/h3&gt;
&lt;h4&gt;New Posts&lt;/h4&gt;
&lt;p&gt;In order to get more familiar with the workings of the platform/ try to customize what I was doing, I decided to write my own function to help speed up the process of writing a new blog. Pelican makes this quite simple with the fabfile.py, which allows you to create new functions for anything that you may want to customize.&lt;/p&gt;
&lt;p&gt;In my case, I wanted to be able to create new posts from the command line. So by typing the following I can now create a new Markdown file in my content folder with the title, slug, date, etc. preformatted.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;fab newpost:&lt;span class="s2"&gt;&amp;quot;title of my post&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The code that makes this happen is just a simple function that fills in a prespecified template.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;TEMPLATE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s"&gt;Title: {title}&lt;/span&gt;
&lt;span class="s"&gt;Date: {year}-{month}-{day} {hour}:{minute}&lt;/span&gt;
&lt;span class="s"&gt;Category:&lt;/span&gt;
&lt;span class="s"&gt;Slug: {slug}&lt;/span&gt;
&lt;span class="s"&gt;Summary:&lt;/span&gt;
&lt;span class="s"&gt;Status: draft&lt;/span&gt;
&lt;span class="s"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;newpost&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;today&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;today&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;slug&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;_&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;f_create&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;content/{}{:0&amp;gt;2}{:0&amp;gt;2}_{}.md&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;today&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;year&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;today&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;month&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;today&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;day&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slug&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TEMPLATE&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                &lt;span class="n"&gt;year&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;today&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;year&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                &lt;span class="n"&gt;month&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;today&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;month&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                &lt;span class="n"&gt;day&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;today&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;day&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                &lt;span class="n"&gt;hour&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;today&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hour&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                &lt;span class="n"&gt;minute&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;today&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minute&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                &lt;span class="n"&gt;slug&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;slug&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f_create&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
         &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;File created -&amp;gt; &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;f_create&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;Themes&lt;/h4&gt;
&lt;p&gt;I also wanted to experiment with HTML/ CSS and modify the themes that I was using on my blog. I started with the &lt;a href="https://github.com/gfidente/pelican-svbhack"&gt;SVBHACK&lt;/a&gt; theme but did not really like that the index and archives links were at the top of the page, which seemed to clutter the simplicity of the page. This was a pretty simple customization that I fixed by changing some of the HTML template code to move the links around but now the top of the page is clean!&lt;/p&gt;
&lt;p&gt;Original:&lt;/p&gt;
&lt;p&gt;&lt;img alt="original index and archives" src="/images/index_archives_orig.png" /&gt;&lt;/p&gt;
&lt;p&gt;Modified:&lt;/p&gt;
&lt;p&gt;&lt;img alt="new archives" src="/images/archives_new.png" /&gt;&lt;/p&gt;
&lt;p&gt;I was also interested in customizing the color of the side column and so that took some time digging through the style sheet to make it look the way I wanted. Anyways, now things seem to be the way I want them and I hope that they don't break.&lt;/p&gt;
&lt;h3&gt;Writing and Viewing&lt;/h3&gt;
&lt;p&gt;Pelican actually makes it surprisingly simple to write and view what has been written.&lt;/p&gt;
&lt;p&gt;With the function that I wrote above, I can now create first drafts pretty quickly, then when I want to see the post on my blog, Pelican allows for a local server to be created to view the changes. What is most awesome is that if I use&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;make devserver
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I can actually have the page regenerate each time with new content and all I have to do is refresh the page. So now I can make sure that everything is formatted correctly before I publish my posts.&lt;/p&gt;
&lt;h3&gt;Final Thoughts&lt;/h3&gt;
&lt;p&gt;As I learn more about Pelican and blogging in general, I may update this post to include new information about customizations or features that I learn about!&lt;/p&gt;</summary></entry><entry><title>Hello World!</title><link href="http://jeffwen.github.io/2015/11/27/hello-world" rel="alternate"></link><updated>2015-11-27T03:15:00-08:00</updated><author><name>Jeff Wen</name></author><id>tag:jeffwen.github.io,2015-11-27:2015/11/27/hello-world</id><summary type="html">&lt;p&gt;&lt;em&gt;November 27, 2015&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Hello everyone, my name is Jeff. I've started this blog to keep track of the things that I am up to and also to share about exciting things that I am learning. Thanks for stopping by!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Hello World!&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary></entry></feed>